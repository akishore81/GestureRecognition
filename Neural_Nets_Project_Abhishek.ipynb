{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "import datetime\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Dropout, Flatten, BatchNormalization, Activation, Conv3D, MaxPooling3D, TimeDistributed\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '/home/datasets/Project_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator():\n",
    "    def __init__(self):\n",
    "        'Initialization'\n",
    "        self.train_doc = np.random.permutation(open(DATASET_PATH + 'train.csv').readlines())\n",
    "        self.val_doc = np.random.permutation(open(DATASET_PATH + 'val.csv').readlines())\n",
    "        \n",
    "        self.train_path = DATASET_PATH + 'train'\n",
    "        self.val_path = DATASET_PATH + 'val'\n",
    "        \n",
    "        self.num_train_sequences = len(self.train_doc)\n",
    "        self.num_val_sequences = len(self.val_doc)\n",
    "        \n",
    "        self.img_idx = [0,2,4,6,8,10,12,14,16,18,20,22,24,25,26,27,28,29]\n",
    "    \n",
    "    def initialize_parameters(self,batch_size=10,img_height=100,img_width=100,num_epochs=5,\n",
    "                              n_channels=3,ablation=None,mode='train'):\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.channels = n_channels\n",
    "        self.num_classes = 5\n",
    "        self.frames = 30\n",
    "    \n",
    "    def generator(self,source_path, folder_list, transform=False):\n",
    "        batch_size=self.batch_size\n",
    "        \n",
    "        while True:\n",
    "            t = np.random.permutation(folder_list)\n",
    "            num_batches = np.floor(len(folder_list)/self.batch_size).astype(int)\n",
    "            \n",
    "            for batch in range(num_batches): # we iterate over the number of batches\n",
    "                batch_data, batch_labels = self.fetch_batch(source_path,t,batch,self.batch_size,self.img_idx,transform)\n",
    "                yield batch_data, batch_labels\n",
    "            \n",
    "            pending_batches = (len(folder_list) - num_batches*self.batch_size)\n",
    "            \n",
    "            if pending_batches > 0:\n",
    "                batch_data, batch_labels = self.fetch_batch(source_path,t,batch,pending_batches,self.img_idx,transform)\n",
    "                yield batch_data, batch_labels\n",
    "    \n",
    "    def fetch_batch(self,source_path,t,batch,batch_size,img_idx,transform):\n",
    "        # x is the number of images you use for each video, \n",
    "        # (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "        batch_data = np.zeros((batch_size,len(img_idx),self.img_height,self.img_width,3))\n",
    "        batch_labels = np.zeros((batch_size,5))\n",
    "        \n",
    "        if (transform):\n",
    "            batch_data_affine = np.zeros((batch_size,len(img_idx),self.img_height,self.img_width,3))\n",
    "\n",
    "        for folder in range(batch_size):\n",
    "            # read all the images in the folder\n",
    "            imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) \n",
    "            \n",
    "            img_idx = self.img_idx\n",
    "            \n",
    "            for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                image = cv2.imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "\n",
    "                if image.shape[0] != image.shape[1]:\n",
    "                    image = image[0:120, 10:150]\n",
    "                \n",
    "                image = cv2.resize(image, (self.img_height,self.img_width), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "                image = image/255\n",
    "                \n",
    "                batch_data[folder,idx,:,:,0] = image[:,:,0]\n",
    "                batch_data[folder,idx,:,:,1] = image[:,:,1]\n",
    "                batch_data[folder,idx,:,:,2] = image[:,:,2]\n",
    "                \n",
    "                #Affine transformation to shift image up/down or right/left\n",
    "                if (transform):\n",
    "                    height, width = image.shape[:2]\n",
    "                    tx, ty = width / 4, height / 4\n",
    "                    tx = np.random.randint(-tx,tx)\n",
    "                    ty = np.random.randint(-ty,ty)\n",
    "                    translation_matrix = np.array([[1, 0, tx],\n",
    "                                                   [0, 1, ty]], dtype=np.float32)\n",
    "\n",
    "                    translated_image = cv2.warpAffine(src=image, M=translation_matrix, dsize=(width, height))\n",
    "\n",
    "                    batch_data_affine[folder,idx,:,:,0] = translated_image[:,:,0]\n",
    "                    batch_data_affine[folder,idx,:,:,1] = translated_image[:,:,1]\n",
    "                    batch_data_affine[folder,idx,:,:,2] = translated_image[:,:,2]\n",
    "\n",
    "            batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "\n",
    "        if (transform):\n",
    "            batch_data=np.concatenate([batch_data,batch_data_affine])\n",
    "            batch_labels=np.concatenate([batch_labels,batch_labels])\n",
    "        \n",
    "        return (batch_data, batch_labels)\n",
    "    \n",
    "    def train_model(self,model,transform=False):\n",
    "        train_generator = self.generator(self.train_path, self.train_doc,transform)\n",
    "        val_generator = self.generator(self.val_path, self.val_doc,transform)\n",
    "        \n",
    "        curr_dt_time = datetime.datetime.now()\n",
    "        \n",
    "        model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "        if not os.path.exists(model_name):\n",
    "            os.mkdir(model_name)\n",
    "\n",
    "        filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "        \n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto',save_freq = 'epoch')\n",
    "        \n",
    "        LR = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, verbose=1) # write the REducelronplateau code here\n",
    "        \n",
    "        earlystop = EarlyStopping(monitor=\"val_loss\", min_delta=0,patience=10,verbose=1)\n",
    "        \n",
    "        callbacks_list = [checkpoint, LR, earlystop]\n",
    "        \n",
    "        if (self.num_train_sequences%self.batch_size) == 0:\n",
    "            #steps_per_epoch = np.floor(num_train_sequences/batch_size).astype(int)\n",
    "            steps_per_epoch = int(self.num_train_sequences/self.batch_size)\n",
    "        else:\n",
    "            #steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "            steps_per_epoch = (self.num_train_sequences//self.batch_size) + 1\n",
    "\n",
    "        if (self.num_val_sequences%self.batch_size) == 0:\n",
    "            #validation_steps = np.floor(num_val_sequences/batch_size).astype(int)\n",
    "            validation_steps = int(self.num_val_sequences/self.batch_size)\n",
    "        else:\n",
    "            #validation_steps = (num_val_sequences//batch_size) + 1\n",
    "            validation_steps = (self.num_val_sequences//self.batch_size) + 1\n",
    "        \n",
    "        \n",
    "        history = model.fit(train_generator, \n",
    "                            steps_per_epoch=steps_per_epoch, \n",
    "                            epochs=self.num_epochs, \n",
    "                            verbose=1, \n",
    "                            callbacks=callbacks_list, \n",
    "                            validation_data=val_generator, \n",
    "                            validation_steps=validation_steps, \n",
    "                            class_weight=None, workers=1, initial_epoch=0)\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def define_model(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv3DModel1(DataGenerator):\n",
    "\n",
    "    def model_structure(self):\n",
    "        #write your model here\n",
    "        #normalization_layer = layers.experimental.preprocessing.Rescaling(1./255, \n",
    "        #input_shape=(img_frames,img_height, img_width, 3))\n",
    "\n",
    "        #model3d = Sequential([normalization_layer])\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(layers.Conv3D(16,(3,3,3), activation=\"relu\",data_format='channels_first', \n",
    "                                input_shape=(len(self.img_idx),self.img_height, self.img_width, 3)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(layers.MaxPool3D())\n",
    "\n",
    "        model.add(layers.Conv3D(32,(3,3,3), activation=\"relu\",))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(layers.MaxPool3D())\n",
    "\n",
    "        #model.add(layers.Conv3D(64,(3,3,3), activation=\"relu\",))\n",
    "        #model.add(BatchNormalization())\n",
    "        #model.add(layers.MaxPool3D())\n",
    "\n",
    "        #model.add(layers.Conv3D(128,(3,3,3), activation=\"relu\",))\n",
    "        #model.add(BatchNormalization())\n",
    "        #model.add(layers.MaxPool3D())\n",
    "\n",
    "        model.add(layers.Flatten())\n",
    "\n",
    "        #model.add(layers.Dense(128, activation=\"relu\"))\n",
    "        #model.add(BatchNormalization())\n",
    "        #model.add(layers.Dropout(0.5))\n",
    "\n",
    "        model.add(layers.Dense(32, activation=\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(layers.Dropout(0.5))\n",
    "\n",
    "        model.add(layers.Dense(5,activation='softmax'))\n",
    "\n",
    "        optimiser = optimizers.SGD()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_2 (Conv3D)            (None, 16, 148, 148, 1)   7792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 148, 148, 1)   4         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 8, 74, 74, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 6, 72, 72, 32)     896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 72, 72, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 3, 36, 36, 32)     0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 124416)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                3981344   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 3,990,457\n",
      "Trainable params: 3,990,327\n",
      "Non-trainable params: 130\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_3d1=Conv3DModel1()\n",
    "conv_3d1.initialize_parameters(batch_size=10,num_epochs=5,img_height=150,img_width=150)\n",
    "conv_3d1_model=conv_3d1.model_structure()\n",
    "conv_3d1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.6690 - categorical_accuracy: 0.2790\n",
      "Epoch 00001: val_loss improved from inf to 1.61919, saving model to model_init_2021-06-2320_31_32.063034/model-00001-1.66903-0.27903-1.61919-0.21000.h5\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 1.6690 - categorical_accuracy: 0.2790 - val_loss: 1.6192 - val_categorical_accuracy: 0.2100\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.4339 - categorical_accuracy: 0.3725\n",
      "Epoch 00002: val_loss did not improve from 1.61919\n",
      "67/67 [==============================] - 40s 593ms/step - loss: 1.4339 - categorical_accuracy: 0.3725 - val_loss: 1.9499 - val_categorical_accuracy: 0.2800\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.4209 - categorical_accuracy: 0.3982\n",
      "Epoch 00003: val_loss did not improve from 1.61919\n",
      "67/67 [==============================] - 39s 586ms/step - loss: 1.4209 - categorical_accuracy: 0.3982 - val_loss: 1.6689 - val_categorical_accuracy: 0.2600\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.2085 - categorical_accuracy: 0.4992\n",
      "Epoch 00004: val_loss did not improve from 1.61919\n",
      "67/67 [==============================] - 40s 590ms/step - loss: 1.2085 - categorical_accuracy: 0.4992 - val_loss: 2.3888 - val_categorical_accuracy: 0.2800\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.2740 - categorical_accuracy: 0.4766\n",
      "Epoch 00005: val_loss did not improve from 1.61919\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "67/67 [==============================] - 40s 592ms/step - loss: 1.2740 - categorical_accuracy: 0.4766 - val_loss: 3.2009 - val_categorical_accuracy: 0.2600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f53e81a7c50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_3d1.train_model(model=conv_3d1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv3DModel2(DataGenerator):\n",
    "\n",
    "    def model_structure(self):\n",
    "        #write your model here\n",
    "        #normalization_layer = layers.experimental.preprocessing.Rescaling(1./255, \n",
    "        #input_shape=(img_frames,img_height, img_width, 3))\n",
    "\n",
    "        #model3d = Sequential([normalization_layer])\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(layers.Conv3D(16,(3,3,3), activation=\"relu\",data_format='channels_first', \n",
    "                                input_shape=(len(self.img_idx),self.img_height, self.img_width, 3)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(layers.MaxPool3D())\n",
    "\n",
    "        model.add(layers.Conv3D(32,(3,3,3), activation=\"relu\",))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(layers.MaxPool3D())\n",
    "\n",
    "        #model.add(layers.Conv3D(64,(3,3,3), activation=\"relu\",))\n",
    "        #model.add(BatchNormalization())\n",
    "        #model.add(layers.MaxPool3D())\n",
    "\n",
    "        #model.add(layers.Conv3D(128,(3,3,3), activation=\"relu\",))\n",
    "        #model.add(BatchNormalization())\n",
    "        #model.add(layers.MaxPool3D())\n",
    "\n",
    "        model.add(layers.Flatten())\n",
    "\n",
    "        #model.add(layers.Dense(128, activation=\"relu\"))\n",
    "        #model.add(BatchNormalization())\n",
    "        #model.add(layers.Dropout(0.5))\n",
    "\n",
    "        model.add(layers.Dense(32, activation=\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(layers.Dropout(0.5))\n",
    "\n",
    "        model.add(layers.Dense(5,activation='softmax'))\n",
    "\n",
    "        optimiser = optimizers.SGD(lr=0.001)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_6 (Conv3D)            (None, 16, 148, 148, 1)   7792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 16, 148, 148, 1)   4         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 8, 74, 74, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 6, 72, 72, 32)     896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 6, 72, 72, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 3, 36, 36, 32)     0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 124416)            0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                3981344   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 3,990,457\n",
      "Trainable params: 3,990,327\n",
      "Non-trainable params: 130\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_3d2=Conv3DModel2()\n",
    "conv_3d2.initialize_parameters(batch_size=10,num_epochs=5,img_height=150,img_width=150)\n",
    "conv_3d2_model=conv_3d2.model_structure()\n",
    "conv_3d2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.6390 - categorical_accuracy: 0.3560\n",
      "Epoch 00001: val_loss improved from inf to 2.21542, saving model to model_init_2021-06-2320_59_01.439695/model-00001-1.63895-0.35596-2.21542-0.21000.h5\n",
      "67/67 [==============================] - 39s 587ms/step - loss: 1.6390 - categorical_accuracy: 0.3560 - val_loss: 2.2154 - val_categorical_accuracy: 0.2100\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.2922 - categorical_accuracy: 0.4555\n",
      "Epoch 00002: val_loss did not improve from 2.21542\n",
      "67/67 [==============================] - 39s 587ms/step - loss: 1.2922 - categorical_accuracy: 0.4555 - val_loss: 3.2276 - val_categorical_accuracy: 0.2400\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.0856 - categorical_accuracy: 0.5822\n",
      "Epoch 00003: val_loss did not improve from 2.21542\n",
      "67/67 [==============================] - 39s 583ms/step - loss: 1.0856 - categorical_accuracy: 0.5822 - val_loss: 3.6045 - val_categorical_accuracy: 0.2100\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.9118 - categorical_accuracy: 0.6757\n",
      "Epoch 00004: val_loss did not improve from 2.21542\n",
      "67/67 [==============================] - 39s 582ms/step - loss: 0.9118 - categorical_accuracy: 0.6757 - val_loss: 2.9748 - val_categorical_accuracy: 0.2100\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8299 - categorical_accuracy: 0.7481\n",
      "Epoch 00005: val_loss did not improve from 2.21542\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "67/67 [==============================] - 39s 587ms/step - loss: 0.8299 - categorical_accuracy: 0.7481 - val_loss: 2.4578 - val_categorical_accuracy: 0.2300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f546eb45c88>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_3d2.train_model(model=conv_3d2_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_8 (Conv3D)            (None, 16, 148, 148, 1)   7792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 16, 148, 148, 1)   4         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 8, 74, 74, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 6, 72, 72, 32)     896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 6, 72, 72, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3 (None, 3, 36, 36, 32)     0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 124416)            0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                3981344   \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 3,990,457\n",
      "Trainable params: 3,990,327\n",
      "Non-trainable params: 130\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_3d2=Conv3DModel2()\n",
    "conv_3d2.initialize_parameters(batch_size=10,num_epochs=10,img_height=150,img_width=150)\n",
    "conv_3d2_model=conv_3d2.model_structure()\n",
    "conv_3d2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.7122 - categorical_accuracy: 0.3318\n",
      "Epoch 00001: val_loss improved from inf to 1.72030, saving model to model_init_2021-06-2321_04_11.241700/model-00001-1.71219-0.33183-1.72030-0.21000.h5\n",
      "67/67 [==============================] - 40s 590ms/step - loss: 1.7122 - categorical_accuracy: 0.3318 - val_loss: 1.7203 - val_categorical_accuracy: 0.2100\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.3428 - categorical_accuracy: 0.4555\n",
      "Epoch 00002: val_loss did not improve from 1.72030\n",
      "67/67 [==============================] - 39s 586ms/step - loss: 1.3428 - categorical_accuracy: 0.4555 - val_loss: 2.8117 - val_categorical_accuracy: 0.2100\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.1191 - categorical_accuracy: 0.5475\n",
      "Epoch 00003: val_loss did not improve from 1.72030\n",
      "67/67 [==============================] - 39s 583ms/step - loss: 1.1191 - categorical_accuracy: 0.5475 - val_loss: 2.6116 - val_categorical_accuracy: 0.2000\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.9059 - categorical_accuracy: 0.6652\n",
      "Epoch 00004: val_loss did not improve from 1.72030\n",
      "67/67 [==============================] - 39s 588ms/step - loss: 0.9059 - categorical_accuracy: 0.6652 - val_loss: 3.1001 - val_categorical_accuracy: 0.2000\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7680 - categorical_accuracy: 0.7134\n",
      "Epoch 00005: val_loss did not improve from 1.72030\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "67/67 [==============================] - 39s 584ms/step - loss: 0.7680 - categorical_accuracy: 0.7134 - val_loss: 2.7494 - val_categorical_accuracy: 0.2100\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6720 - categorical_accuracy: 0.7828\n",
      "Epoch 00006: val_loss did not improve from 1.72030\n",
      "67/67 [==============================] - 39s 587ms/step - loss: 0.6720 - categorical_accuracy: 0.7828 - val_loss: 2.1539 - val_categorical_accuracy: 0.2300\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6467 - categorical_accuracy: 0.7647\n",
      "Epoch 00007: val_loss improved from 1.72030 to 1.37550, saving model to model_init_2021-06-2321_04_11.241700/model-00007-0.64673-0.76471-1.37550-0.43000.h5\n",
      "67/67 [==============================] - 39s 583ms/step - loss: 0.6467 - categorical_accuracy: 0.7647 - val_loss: 1.3755 - val_categorical_accuracy: 0.4300\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6236 - categorical_accuracy: 0.7828\n",
      "Epoch 00008: val_loss improved from 1.37550 to 1.08212, saving model to model_init_2021-06-2321_04_11.241700/model-00008-0.62359-0.78281-1.08212-0.59000.h5\n",
      "67/67 [==============================] - 39s 577ms/step - loss: 0.6236 - categorical_accuracy: 0.7828 - val_loss: 1.0821 - val_categorical_accuracy: 0.5900\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6283 - categorical_accuracy: 0.8130\n",
      "Epoch 00009: val_loss improved from 1.08212 to 0.91450, saving model to model_init_2021-06-2321_04_11.241700/model-00009-0.62835-0.81297-0.91450-0.70000.h5\n",
      "67/67 [==============================] - 40s 591ms/step - loss: 0.6283 - categorical_accuracy: 0.8130 - val_loss: 0.9145 - val_categorical_accuracy: 0.7000\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5747 - categorical_accuracy: 0.8341\n",
      "Epoch 00010: val_loss improved from 0.91450 to 0.77543, saving model to model_init_2021-06-2321_04_11.241700/model-00010-0.57473-0.83409-0.77543-0.70000.h5\n",
      "67/67 [==============================] - 40s 591ms/step - loss: 0.5747 - categorical_accuracy: 0.8341 - val_loss: 0.7754 - val_categorical_accuracy: 0.7000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f546e950cc0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_3d2.train_model(model=conv_3d2_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv3DModel3(DataGenerator):\n",
    "\n",
    "    def model_structure(self):\n",
    "        #write your model here\n",
    "        #normalization_layer = layers.experimental.preprocessing.Rescaling(1./255, \n",
    "        #input_shape=(img_frames,img_height, img_width, 3))\n",
    "\n",
    "        #model3d = Sequential([normalization_layer])\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(layers.Conv3D(16,(3,3,3), activation=\"relu\",data_format='channels_first', \n",
    "                                input_shape=(len(self.img_idx),self.img_height, self.img_width, 3)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(layers.MaxPool3D())\n",
    "\n",
    "        model.add(layers.Conv3D(32,(3,3,3), activation=\"relu\",))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(layers.MaxPool3D())\n",
    "\n",
    "        #model.add(layers.Conv3D(64,(3,3,3), activation=\"relu\",))\n",
    "        #model.add(BatchNormalization())\n",
    "        #model.add(layers.MaxPool3D())\n",
    "\n",
    "        #model.add(layers.Conv3D(128,(3,3,3), activation=\"relu\",))\n",
    "        #model.add(BatchNormalization())\n",
    "        #model.add(layers.MaxPool3D())\n",
    "\n",
    "        model.add(layers.Flatten())\n",
    "\n",
    "        #model.add(layers.Dense(128, activation=\"relu\"))\n",
    "        #model.add(BatchNormalization())\n",
    "        #model.add(layers.Dropout(0.5))\n",
    "\n",
    "        model.add(layers.Dense(32, activation=\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(layers.Dropout(0.5))\n",
    "\n",
    "        model.add(layers.Dense(5,activation='softmax'))\n",
    "\n",
    "        optimiser = optimizers.SGD(lr=0.0001)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_12 (Conv3D)           (None, 16, 148, 148, 1)   7792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 16, 148, 148, 1)   4         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_12 (MaxPooling (None, 8, 74, 74, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_13 (Conv3D)           (None, 6, 72, 72, 32)     896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 6, 72, 72, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_13 (MaxPooling (None, 3, 36, 36, 32)     0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 124416)            0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 32)                3981344   \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 3,990,457\n",
      "Trainable params: 3,990,327\n",
      "Non-trainable params: 130\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_3d3=Conv3DModel3()\n",
    "conv_3d3.initialize_parameters(batch_size=10,num_epochs=15,img_height=150,img_width=150)\n",
    "conv_3d3_model=conv_3d3.model_structure()\n",
    "conv_3d3_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.8115 - categorical_accuracy: 0.2745\n",
      "Epoch 00001: val_loss improved from inf to 2.19505, saving model to model_init_2021-06-2321_14_49.604082/model-00001-1.81152-0.27451-2.19505-0.16000.h5\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 1.8115 - categorical_accuracy: 0.2745 - val_loss: 2.1950 - val_categorical_accuracy: 0.1600\n",
      "Epoch 2/15\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.5128 - categorical_accuracy: 0.3846\n",
      "Epoch 00002: val_loss did not improve from 2.19505\n",
      "67/67 [==============================] - 39s 589ms/step - loss: 1.5128 - categorical_accuracy: 0.3846 - val_loss: 2.7469 - val_categorical_accuracy: 0.1500\n",
      "Epoch 3/15\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.3771 - categorical_accuracy: 0.4404\n",
      "Epoch 00003: val_loss did not improve from 2.19505\n",
      "67/67 [==============================] - 39s 584ms/step - loss: 1.3771 - categorical_accuracy: 0.4404 - val_loss: 2.4731 - val_categorical_accuracy: 0.1700\n",
      "Epoch 4/15\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.2192 - categorical_accuracy: 0.5113\n",
      "Epoch 00004: val_loss did not improve from 2.19505\n",
      "67/67 [==============================] - 39s 583ms/step - loss: 1.2192 - categorical_accuracy: 0.5113 - val_loss: 2.3102 - val_categorical_accuracy: 0.1700\n",
      "Epoch 5/15\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.1061 - categorical_accuracy: 0.5596\n",
      "Epoch 00005: val_loss improved from 2.19505 to 2.04665, saving model to model_init_2021-06-2321_14_49.604082/model-00005-1.10609-0.55958-2.04665-0.25000.h5\n",
      "67/67 [==============================] - 39s 582ms/step - loss: 1.1061 - categorical_accuracy: 0.5596 - val_loss: 2.0467 - val_categorical_accuracy: 0.2500\n",
      "Epoch 6/15\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.0326 - categorical_accuracy: 0.6063\n",
      "Epoch 00006: val_loss improved from 2.04665 to 1.52639, saving model to model_init_2021-06-2321_14_49.604082/model-00006-1.03256-0.60633-1.52639-0.33000.h5\n",
      "67/67 [==============================] - 40s 594ms/step - loss: 1.0326 - categorical_accuracy: 0.6063 - val_loss: 1.5264 - val_categorical_accuracy: 0.3300\n",
      "Epoch 7/15\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.0091 - categorical_accuracy: 0.6094\n",
      "Epoch 00007: val_loss improved from 1.52639 to 1.39032, saving model to model_init_2021-06-2321_14_49.604082/model-00007-1.00913-0.60935-1.39032-0.43000.h5\n",
      "67/67 [==============================] - 39s 579ms/step - loss: 1.0091 - categorical_accuracy: 0.6094 - val_loss: 1.3903 - val_categorical_accuracy: 0.4300\n",
      "Epoch 8/15\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.9577 - categorical_accuracy: 0.6320\n",
      "Epoch 00008: val_loss improved from 1.39032 to 1.17083, saving model to model_init_2021-06-2321_14_49.604082/model-00008-0.95769-0.63198-1.17083-0.56000.h5\n",
      "67/67 [==============================] - 39s 580ms/step - loss: 0.9577 - categorical_accuracy: 0.6320 - val_loss: 1.1708 - val_categorical_accuracy: 0.5600\n",
      "Epoch 9/15\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8083 - categorical_accuracy: 0.7134\n",
      "Epoch 00009: val_loss improved from 1.17083 to 1.05082, saving model to model_init_2021-06-2321_14_49.604082/model-00009-0.80829-0.71342-1.05082-0.63000.h5\n",
      "67/67 [==============================] - 39s 575ms/step - loss: 0.8083 - categorical_accuracy: 0.7134 - val_loss: 1.0508 - val_categorical_accuracy: 0.6300\n",
      "Epoch 10/15\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8519 - categorical_accuracy: 0.6772\n",
      "Epoch 00010: val_loss did not improve from 1.05082\n",
      "67/67 [==============================] - 39s 575ms/step - loss: 0.8519 - categorical_accuracy: 0.6772 - val_loss: 1.1190 - val_categorical_accuracy: 0.5700\n",
      "Epoch 11/15\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7649 - categorical_accuracy: 0.7285\n",
      "Epoch 00011: val_loss improved from 1.05082 to 0.97957, saving model to model_init_2021-06-2321_14_49.604082/model-00011-0.76494-0.72851-0.97957-0.67000.h5\n",
      "67/67 [==============================] - 38s 572ms/step - loss: 0.7649 - categorical_accuracy: 0.7285 - val_loss: 0.9796 - val_categorical_accuracy: 0.6700\n",
      "Epoch 12/15\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6960 - categorical_accuracy: 0.7632\n",
      "Epoch 00012: val_loss did not improve from 0.97957\n",
      "67/67 [==============================] - 39s 581ms/step - loss: 0.6960 - categorical_accuracy: 0.7632 - val_loss: 1.0722 - val_categorical_accuracy: 0.5600\n",
      "Epoch 13/15\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7134 - categorical_accuracy: 0.7511\n",
      "Epoch 00013: val_loss did not improve from 0.97957\n",
      "67/67 [==============================] - 39s 582ms/step - loss: 0.7134 - categorical_accuracy: 0.7511 - val_loss: 0.9836 - val_categorical_accuracy: 0.6300\n",
      "Epoch 14/15\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6192 - categorical_accuracy: 0.7949\n",
      "Epoch 00014: val_loss did not improve from 0.97957\n",
      "67/67 [==============================] - 39s 579ms/step - loss: 0.6192 - categorical_accuracy: 0.7949 - val_loss: 1.6929 - val_categorical_accuracy: 0.4400\n",
      "Epoch 15/15\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6716 - categorical_accuracy: 0.7602\n",
      "Epoch 00015: val_loss improved from 0.97957 to 0.96850, saving model to model_init_2021-06-2321_14_49.604082/model-00015-0.67162-0.76018-0.96850-0.67000.h5\n",
      "67/67 [==============================] - 39s 578ms/step - loss: 0.6716 - categorical_accuracy: 0.7602 - val_loss: 0.9685 - val_categorical_accuracy: 0.6700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f546fdbd198>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_3d3.train_model(model=conv_3d3_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_14 (Conv3D)           (None, 16, 148, 148, 1)   7792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 16, 148, 148, 1)   4         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_14 (MaxPooling (None, 8, 74, 74, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_15 (Conv3D)           (None, 6, 72, 72, 32)     896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 6, 72, 72, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_15 (MaxPooling (None, 3, 36, 36, 32)     0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 124416)            0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                3981344   \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 3,990,457\n",
      "Trainable params: 3,990,327\n",
      "Non-trainable params: 130\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_3d4=Conv3DModel3()\n",
    "conv_3d4.initialize_parameters(batch_size=20,num_epochs=15,img_height=150,img_width=150)\n",
    "conv_3d4_model=conv_3d4.model_structure()\n",
    "conv_3d4_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "33/34 [============================>.] - ETA: 0s - loss: 2.0389 - categorical_accuracy: 0.2970\n",
      "Epoch 00001: val_loss improved from inf to 1.59088, saving model to model_init_2021-06-2321_26_51.045085/model-00001-2.04375-0.29563-1.59088-0.24000.h5\n",
      "34/34 [==============================] - 39s 1s/step - loss: 2.0437 - categorical_accuracy: 0.2956 - val_loss: 1.5909 - val_categorical_accuracy: 0.2400\n",
      "Epoch 2/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.5787 - categorical_accuracy: 0.3756\n",
      "Epoch 00002: val_loss did not improve from 1.59088\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.5787 - categorical_accuracy: 0.3756 - val_loss: 1.6567 - val_categorical_accuracy: 0.3100\n",
      "Epoch 3/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.3593 - categorical_accuracy: 0.4751\n",
      "Epoch 00003: val_loss improved from 1.59088 to 1.52043, saving model to model_init_2021-06-2321_26_51.045085/model-00003-1.35926-0.47511-1.52043-0.27000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.3593 - categorical_accuracy: 0.4751 - val_loss: 1.5204 - val_categorical_accuracy: 0.2700\n",
      "Epoch 4/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.3025 - categorical_accuracy: 0.5038\n",
      "Epoch 00004: val_loss did not improve from 1.52043\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.3025 - categorical_accuracy: 0.5038 - val_loss: 1.7365 - val_categorical_accuracy: 0.2500\n",
      "Epoch 5/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.1160 - categorical_accuracy: 0.5777\n",
      "Epoch 00005: val_loss improved from 1.52043 to 1.51654, saving model to model_init_2021-06-2321_26_51.045085/model-00005-1.11600-0.57768-1.51654-0.28000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.1160 - categorical_accuracy: 0.5777 - val_loss: 1.5165 - val_categorical_accuracy: 0.2800\n",
      "Epoch 6/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0657 - categorical_accuracy: 0.5958\n",
      "Epoch 00006: val_loss did not improve from 1.51654\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.0657 - categorical_accuracy: 0.5958 - val_loss: 1.5346 - val_categorical_accuracy: 0.3600\n",
      "Epoch 7/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0308 - categorical_accuracy: 0.5958\n",
      "Epoch 00007: val_loss improved from 1.51654 to 1.44567, saving model to model_init_2021-06-2321_26_51.045085/model-00007-1.03084-0.59578-1.44567-0.38000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.0308 - categorical_accuracy: 0.5958 - val_loss: 1.4457 - val_categorical_accuracy: 0.3800\n",
      "Epoch 8/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9963 - categorical_accuracy: 0.6109\n",
      "Epoch 00008: val_loss improved from 1.44567 to 1.44443, saving model to model_init_2021-06-2321_26_51.045085/model-00008-0.99629-0.61086-1.44443-0.39000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.9963 - categorical_accuracy: 0.6109 - val_loss: 1.4444 - val_categorical_accuracy: 0.3900\n",
      "Epoch 9/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9342 - categorical_accuracy: 0.6395\n",
      "Epoch 00009: val_loss improved from 1.44443 to 1.25542, saving model to model_init_2021-06-2321_26_51.045085/model-00009-0.93416-0.63952-1.25542-0.49000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.9342 - categorical_accuracy: 0.6395 - val_loss: 1.2554 - val_categorical_accuracy: 0.4900\n",
      "Epoch 10/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.8587 - categorical_accuracy: 0.6817\n",
      "Epoch 00010: val_loss did not improve from 1.25542\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.8587 - categorical_accuracy: 0.6817 - val_loss: 1.3364 - val_categorical_accuracy: 0.5100\n",
      "Epoch 11/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.8412 - categorical_accuracy: 0.6727\n",
      "Epoch 00011: val_loss improved from 1.25542 to 1.23273, saving model to model_init_2021-06-2321_26_51.045085/model-00011-0.84121-0.67270-1.23273-0.47000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.8412 - categorical_accuracy: 0.6727 - val_loss: 1.2327 - val_categorical_accuracy: 0.4700\n",
      "Epoch 12/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.7938 - categorical_accuracy: 0.7089\n",
      "Epoch 00012: val_loss improved from 1.23273 to 1.14772, saving model to model_init_2021-06-2321_26_51.045085/model-00012-0.79377-0.70890-1.14772-0.58000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.7938 - categorical_accuracy: 0.7089 - val_loss: 1.1477 - val_categorical_accuracy: 0.5800\n",
      "Epoch 13/15\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.7667 - categorical_accuracy: 0.6909\n",
      "Epoch 00013: val_loss improved from 1.14772 to 1.14446, saving model to model_init_2021-06-2321_26_51.045085/model-00013-0.76426-0.69231-1.14446-0.56000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.7643 - categorical_accuracy: 0.6923 - val_loss: 1.1445 - val_categorical_accuracy: 0.5600\n",
      "Epoch 14/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6822 - categorical_accuracy: 0.7587\n",
      "Epoch 00014: val_loss improved from 1.14446 to 1.11139, saving model to model_init_2021-06-2321_26_51.045085/model-00014-0.68218-0.75867-1.11139-0.62000.h5\n",
      "34/34 [==============================] - 37s 1s/step - loss: 0.6822 - categorical_accuracy: 0.7587 - val_loss: 1.1114 - val_categorical_accuracy: 0.6200\n",
      "Epoch 15/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6292 - categorical_accuracy: 0.7873\n",
      "Epoch 00015: val_loss did not improve from 1.11139\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.6292 - categorical_accuracy: 0.7873 - val_loss: 1.1221 - val_categorical_accuracy: 0.5900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f53e0328b70>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_3d4.train_model(model=conv_3d4_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_18 (Conv3D)           (None, 16, 148, 148, 1)   7792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 16, 148, 148, 1)   4         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_18 (MaxPooling (None, 8, 74, 74, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_19 (Conv3D)           (None, 6, 72, 72, 32)     896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 6, 72, 72, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_19 (MaxPooling (None, 3, 36, 36, 32)     0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 124416)            0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 32)                3981344   \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 3,990,457\n",
      "Trainable params: 3,990,327\n",
      "Non-trainable params: 130\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_3d5=Conv3DModel3()\n",
    "conv_3d5.initialize_parameters(batch_size=20,num_epochs=25,img_height=150,img_width=150)\n",
    "conv_3d5_model=conv_3d5.model_structure()\n",
    "conv_3d5_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 2.0028 - categorical_accuracy: 0.2851\n",
      "Epoch 00001: val_loss improved from inf to 1.76088, saving model to model_init_2021-06-2321_54_27.730621/model-00001-2.00279-0.28507-1.76088-0.16000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 2.0028 - categorical_accuracy: 0.2851 - val_loss: 1.7609 - val_categorical_accuracy: 0.1600\n",
      "Epoch 2/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.5251 - categorical_accuracy: 0.4163\n",
      "Epoch 00002: val_loss did not improve from 1.76088\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.5251 - categorical_accuracy: 0.4163 - val_loss: 2.2840 - val_categorical_accuracy: 0.1500\n",
      "Epoch 3/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.3102 - categorical_accuracy: 0.5038\n",
      "Epoch 00003: val_loss did not improve from 1.76088\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.3102 - categorical_accuracy: 0.5038 - val_loss: 2.7172 - val_categorical_accuracy: 0.1500\n",
      "Epoch 4/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.1636 - categorical_accuracy: 0.5234\n",
      "Epoch 00004: val_loss did not improve from 1.76088\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.1636 - categorical_accuracy: 0.5234 - val_loss: 2.9158 - val_categorical_accuracy: 0.1600\n",
      "Epoch 5/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0749 - categorical_accuracy: 0.5596\n",
      "Epoch 00005: val_loss did not improve from 1.76088\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.0749 - categorical_accuracy: 0.5596 - val_loss: 3.0088 - val_categorical_accuracy: 0.1600\n",
      "Epoch 6/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9786 - categorical_accuracy: 0.6440\n",
      "Epoch 00006: val_loss did not improve from 1.76088\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.9786 - categorical_accuracy: 0.6440 - val_loss: 2.9587 - val_categorical_accuracy: 0.1600\n",
      "Epoch 7/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9137 - categorical_accuracy: 0.6621\n",
      "Epoch 00007: val_loss did not improve from 1.76088\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.9137 - categorical_accuracy: 0.6621 - val_loss: 2.7626 - val_categorical_accuracy: 0.1700\n",
      "Epoch 8/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9511 - categorical_accuracy: 0.6305\n",
      "Epoch 00008: val_loss did not improve from 1.76088\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.9511 - categorical_accuracy: 0.6305 - val_loss: 2.6691 - val_categorical_accuracy: 0.1600\n",
      "Epoch 9/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9351 - categorical_accuracy: 0.6425\n",
      "Epoch 00009: val_loss did not improve from 1.76088\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.9351 - categorical_accuracy: 0.6425 - val_loss: 2.4525 - val_categorical_accuracy: 0.1300\n",
      "Epoch 10/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9070 - categorical_accuracy: 0.6682\n",
      "Epoch 00010: val_loss did not improve from 1.76088\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.9070 - categorical_accuracy: 0.6682 - val_loss: 2.0009 - val_categorical_accuracy: 0.1600\n",
      "Epoch 11/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9400 - categorical_accuracy: 0.6395\n",
      "Epoch 00011: val_loss did not improve from 1.76088\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.9400 - categorical_accuracy: 0.6395 - val_loss: 1.7867 - val_categorical_accuracy: 0.2200\n",
      "Epoch 00011: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f533465e470>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_3d5.train_model(model=conv_3d5_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv3DModel4(DataGenerator):\n",
    "\n",
    "    def model_structure(self):\n",
    "        #write your model here\n",
    "        #normalization_layer = layers.experimental.preprocessing.Rescaling(1./255, \n",
    "        #input_shape=(img_frames,img_height, img_width, 3))\n",
    "\n",
    "        #model3d = Sequential([normalization_layer])\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(layers.Conv3D(16,(3,3,3), activation=\"relu\",data_format='channels_first', \n",
    "                                input_shape=(len(self.img_idx),self.img_height, self.img_width, 3)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(layers.MaxPool3D())\n",
    "\n",
    "        model.add(layers.Conv3D(32,(3,3,3), activation=\"relu\",))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(layers.MaxPool3D())\n",
    "\n",
    "        #model.add(layers.Conv3D(64,(3,3,3), activation=\"relu\",))\n",
    "        #model.add(BatchNormalization())\n",
    "        #model.add(layers.MaxPool3D())\n",
    "\n",
    "        #model.add(layers.Conv3D(128,(3,3,3), activation=\"relu\",))\n",
    "        #model.add(BatchNormalization())\n",
    "        #model.add(layers.MaxPool3D())\n",
    "\n",
    "        model.add(layers.Flatten())\n",
    "\n",
    "        #model.add(layers.Dense(128, activation=\"relu\"))\n",
    "        #model.add(BatchNormalization())\n",
    "        #model.add(layers.Dropout(0.5))\n",
    "\n",
    "        model.add(layers.Dense(32, activation=\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(layers.Dropout(0.5))\n",
    "\n",
    "        model.add(layers.Dense(5,activation='softmax'))\n",
    "\n",
    "        optimiser = optimizers.SGD(lr=0.001)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 16, 148, 148, 1)   7792      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 16, 148, 148, 1)   4         \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 8, 74, 74, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 6, 72, 72, 32)     896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 6, 72, 72, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 3, 36, 36, 32)     0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 124416)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                3981344   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 3,990,457\n",
      "Trainable params: 3,990,327\n",
      "Non-trainable params: 130\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_3d6=Conv3DModel4()\n",
    "conv_3d6.initialize_parameters(batch_size=20,num_epochs=25,img_height=150,img_width=150)\n",
    "conv_3d6_model=conv_3d6.model_structure()\n",
    "conv_3d6_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.7036 - categorical_accuracy: 0.2836\n",
      "Epoch 00001: val_loss improved from inf to 1.79321, saving model to model_init_2021-06-2400_30_19.348045/model-00001-1.70360-0.28356-1.79321-0.24000.h5\n",
      "34/34 [==============================] - 39s 1s/step - loss: 1.7036 - categorical_accuracy: 0.2836 - val_loss: 1.7932 - val_categorical_accuracy: 0.2400\n",
      "Epoch 2/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.4079 - categorical_accuracy: 0.4133\n",
      "Epoch 00002: val_loss did not improve from 1.79321\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.4079 - categorical_accuracy: 0.4133 - val_loss: 2.0428 - val_categorical_accuracy: 0.2500\n",
      "Epoch 3/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.2924 - categorical_accuracy: 0.4721\n",
      "Epoch 00003: val_loss did not improve from 1.79321\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.2924 - categorical_accuracy: 0.4721 - val_loss: 2.2337 - val_categorical_accuracy: 0.3100\n",
      "Epoch 4/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.1884 - categorical_accuracy: 0.5370\n",
      "Epoch 00004: val_loss did not improve from 1.79321\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.1884 - categorical_accuracy: 0.5370 - val_loss: 2.3000 - val_categorical_accuracy: 0.1700\n",
      "Epoch 5/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.1754 - categorical_accuracy: 0.5611\n",
      "Epoch 00005: val_loss did not improve from 1.79321\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "34/34 [==============================] - 39s 1s/step - loss: 1.1754 - categorical_accuracy: 0.5611 - val_loss: 2.0282 - val_categorical_accuracy: 0.1900\n",
      "Epoch 6/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.1495 - categorical_accuracy: 0.5460\n",
      "Epoch 00006: val_loss did not improve from 1.79321\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.1495 - categorical_accuracy: 0.5460 - val_loss: 2.1284 - val_categorical_accuracy: 0.1600\n",
      "Epoch 7/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0854 - categorical_accuracy: 0.6078\n",
      "Epoch 00007: val_loss did not improve from 1.79321\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.0854 - categorical_accuracy: 0.6078 - val_loss: 2.1175 - val_categorical_accuracy: 0.1500\n",
      "Epoch 8/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0932 - categorical_accuracy: 0.5973\n",
      "Epoch 00008: val_loss did not improve from 1.79321\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.0932 - categorical_accuracy: 0.5973 - val_loss: 1.7973 - val_categorical_accuracy: 0.2300\n",
      "Epoch 9/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0474 - categorical_accuracy: 0.6335\n",
      "Epoch 00009: val_loss did not improve from 1.79321\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.0474 - categorical_accuracy: 0.6335 - val_loss: 2.0376 - val_categorical_accuracy: 0.2200\n",
      "Epoch 10/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0571 - categorical_accuracy: 0.6154\n",
      "Epoch 00010: val_loss did not improve from 1.79321\n",
      "34/34 [==============================] - 39s 1s/step - loss: 1.0571 - categorical_accuracy: 0.6154 - val_loss: 1.9205 - val_categorical_accuracy: 0.2100\n",
      "Epoch 11/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0487 - categorical_accuracy: 0.6440\n",
      "Epoch 00011: val_loss improved from 1.79321 to 1.74454, saving model to model_init_2021-06-2400_30_19.348045/model-00011-1.04875-0.64404-1.74454-0.36000.h5\n",
      "34/34 [==============================] - 39s 1s/step - loss: 1.0487 - categorical_accuracy: 0.6440 - val_loss: 1.7445 - val_categorical_accuracy: 0.3600\n",
      "Epoch 12/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0696 - categorical_accuracy: 0.6275\n",
      "Epoch 00012: val_loss improved from 1.74454 to 1.60400, saving model to model_init_2021-06-2400_30_19.348045/model-00012-1.06957-0.62745-1.60400-0.45000.h5\n",
      "34/34 [==============================] - 39s 1s/step - loss: 1.0696 - categorical_accuracy: 0.6275 - val_loss: 1.6040 - val_categorical_accuracy: 0.4500\n",
      "Epoch 13/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0615 - categorical_accuracy: 0.6063\n",
      "Epoch 00013: val_loss improved from 1.60400 to 1.54863, saving model to model_init_2021-06-2400_30_19.348045/model-00013-1.06151-0.60633-1.54863-0.42000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.0615 - categorical_accuracy: 0.6063 - val_loss: 1.5486 - val_categorical_accuracy: 0.4200\n",
      "Epoch 14/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0725 - categorical_accuracy: 0.6109\n",
      "Epoch 00014: val_loss improved from 1.54863 to 1.49959, saving model to model_init_2021-06-2400_30_19.348045/model-00014-1.07245-0.61086-1.49959-0.43000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.0725 - categorical_accuracy: 0.6109 - val_loss: 1.4996 - val_categorical_accuracy: 0.4300\n",
      "Epoch 15/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0453 - categorical_accuracy: 0.6380\n",
      "Epoch 00015: val_loss improved from 1.49959 to 1.35588, saving model to model_init_2021-06-2400_30_19.348045/model-00015-1.04529-0.63801-1.35588-0.53000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.0453 - categorical_accuracy: 0.6380 - val_loss: 1.3559 - val_categorical_accuracy: 0.5300\n",
      "Epoch 16/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0573 - categorical_accuracy: 0.6290\n",
      "Epoch 00016: val_loss improved from 1.35588 to 1.32897, saving model to model_init_2021-06-2400_30_19.348045/model-00016-1.05730-0.62896-1.32897-0.52000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.0573 - categorical_accuracy: 0.6290 - val_loss: 1.3290 - val_categorical_accuracy: 0.5200\n",
      "Epoch 17/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0704 - categorical_accuracy: 0.6094\n",
      "Epoch 00017: val_loss improved from 1.32897 to 1.25594, saving model to model_init_2021-06-2400_30_19.348045/model-00017-1.07044-0.60935-1.25594-0.58000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.0704 - categorical_accuracy: 0.6094 - val_loss: 1.2559 - val_categorical_accuracy: 0.5800\n",
      "Epoch 18/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0813 - categorical_accuracy: 0.6048\n",
      "Epoch 00018: val_loss did not improve from 1.25594\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.0813 - categorical_accuracy: 0.6048 - val_loss: 1.2677 - val_categorical_accuracy: 0.5500\n",
      "Epoch 19/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0196 - categorical_accuracy: 0.6591\n",
      "Epoch 00019: val_loss improved from 1.25594 to 1.16849, saving model to model_init_2021-06-2400_30_19.348045/model-00019-1.01961-0.65913-1.16849-0.68000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.0196 - categorical_accuracy: 0.6591 - val_loss: 1.1685 - val_categorical_accuracy: 0.6800\n",
      "Epoch 20/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0697 - categorical_accuracy: 0.6214\n",
      "Epoch 00020: val_loss did not improve from 1.16849\n",
      "34/34 [==============================] - 39s 1s/step - loss: 1.0697 - categorical_accuracy: 0.6214 - val_loss: 1.2093 - val_categorical_accuracy: 0.6500\n",
      "Epoch 21/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0671 - categorical_accuracy: 0.5943\n",
      "Epoch 00021: val_loss did not improve from 1.16849\n",
      "34/34 [==============================] - 39s 1s/step - loss: 1.0671 - categorical_accuracy: 0.5943 - val_loss: 1.2067 - val_categorical_accuracy: 0.6200\n",
      "Epoch 22/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0455 - categorical_accuracy: 0.6275\n",
      "Epoch 00022: val_loss did not improve from 1.16849\n",
      "34/34 [==============================] - 37s 1s/step - loss: 1.0455 - categorical_accuracy: 0.6275 - val_loss: 1.1892 - val_categorical_accuracy: 0.6700\n",
      "Epoch 23/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0730 - categorical_accuracy: 0.6018\n",
      "Epoch 00023: val_loss did not improve from 1.16849\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "34/34 [==============================] - 39s 1s/step - loss: 1.0730 - categorical_accuracy: 0.6018 - val_loss: 1.2258 - val_categorical_accuracy: 0.5900\n",
      "Epoch 24/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0526 - categorical_accuracy: 0.6229\n",
      "Epoch 00024: val_loss improved from 1.16849 to 1.15139, saving model to model_init_2021-06-2400_30_19.348045/model-00024-1.05264-0.62293-1.15139-0.69000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.0526 - categorical_accuracy: 0.6229 - val_loss: 1.1514 - val_categorical_accuracy: 0.6900\n",
      "Epoch 25/25\n",
      "33/34 [============================>.] - ETA: 0s - loss: 1.0406 - categorical_accuracy: 0.6394\n",
      "Epoch 00025: val_loss did not improve from 1.15139\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.0418 - categorical_accuracy: 0.6380 - val_loss: 1.1806 - val_categorical_accuracy: 0.6500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa98c2cfcf8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_3d6.train_model(model=conv_3d6_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_2 (Conv3D)            (None, 16, 148, 148, 1)   7792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 148, 148, 1)   4         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 8, 74, 74, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 6, 72, 72, 32)     896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 72, 72, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 3, 36, 36, 32)     0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 124416)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                3981344   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 3,990,457\n",
      "Trainable params: 3,990,327\n",
      "Non-trainable params: 130\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_3d7=Conv3DModel4()\n",
    "conv_3d7.initialize_parameters(batch_size=25,num_epochs=25,img_height=150,img_width=150)\n",
    "conv_3d7_model=conv_3d7.model_structure()\n",
    "conv_3d7_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "27/27 [==============================] - ETA: 0s - loss: 1.5879 - categorical_accuracy: 0.3967\n",
      "Epoch 00001: val_loss improved from inf to 1.63169, saving model to model_init_2021-06-2400_47_10.093635/model-00001-1.58789-0.39668-1.63169-0.19000.h5\n",
      "27/27 [==============================] - 38s 1s/step - loss: 1.5879 - categorical_accuracy: 0.3967 - val_loss: 1.6317 - val_categorical_accuracy: 0.1900\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - ETA: 0s - loss: 1.0064 - categorical_accuracy: 0.6199\n",
      "Epoch 00002: val_loss did not improve from 1.63169\n",
      "27/27 [==============================] - 38s 1s/step - loss: 1.0064 - categorical_accuracy: 0.6199 - val_loss: 2.2261 - val_categorical_accuracy: 0.1800\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.8544 - categorical_accuracy: 0.6772\n",
      "Epoch 00003: val_loss did not improve from 1.63169\n",
      "27/27 [==============================] - 37s 1s/step - loss: 0.8544 - categorical_accuracy: 0.6772 - val_loss: 2.3544 - val_categorical_accuracy: 0.1500\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6988 - categorical_accuracy: 0.7602\n",
      "Epoch 00004: val_loss did not improve from 1.63169\n",
      "27/27 [==============================] - 38s 1s/step - loss: 0.6988 - categorical_accuracy: 0.7602 - val_loss: 2.3393 - val_categorical_accuracy: 0.2000\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6155 - categorical_accuracy: 0.7919\n",
      "Epoch 00005: val_loss did not improve from 1.63169\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "27/27 [==============================] - 38s 1s/step - loss: 0.6155 - categorical_accuracy: 0.7919 - val_loss: 2.3567 - val_categorical_accuracy: 0.2700\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4990 - categorical_accuracy: 0.8341\n",
      "Epoch 00006: val_loss did not improve from 1.63169\n",
      "27/27 [==============================] - 38s 1s/step - loss: 0.4990 - categorical_accuracy: 0.8341 - val_loss: 2.4291 - val_categorical_accuracy: 0.2200\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5060 - categorical_accuracy: 0.8371\n",
      "Epoch 00007: val_loss did not improve from 1.63169\n",
      "27/27 [==============================] - 38s 1s/step - loss: 0.5060 - categorical_accuracy: 0.8371 - val_loss: 2.4728 - val_categorical_accuracy: 0.2000\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4661 - categorical_accuracy: 0.8643\n",
      "Epoch 00008: val_loss did not improve from 1.63169\n",
      "27/27 [==============================] - 38s 1s/step - loss: 0.4661 - categorical_accuracy: 0.8643 - val_loss: 2.4642 - val_categorical_accuracy: 0.2100\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4532 - categorical_accuracy: 0.8627\n",
      "Epoch 00009: val_loss did not improve from 1.63169\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "27/27 [==============================] - 38s 1s/step - loss: 0.4532 - categorical_accuracy: 0.8627 - val_loss: 2.1828 - val_categorical_accuracy: 0.2300\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4400 - categorical_accuracy: 0.8567\n",
      "Epoch 00010: val_loss did not improve from 1.63169\n",
      "27/27 [==============================] - 37s 1s/step - loss: 0.4400 - categorical_accuracy: 0.8567 - val_loss: 1.9946 - val_categorical_accuracy: 0.2200\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4394 - categorical_accuracy: 0.8839\n",
      "Epoch 00011: val_loss did not improve from 1.63169\n",
      "27/27 [==============================] - 38s 1s/step - loss: 0.4394 - categorical_accuracy: 0.8839 - val_loss: 1.9818 - val_categorical_accuracy: 0.2800\n",
      "Epoch 00011: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faa13f20240>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_3d7.train_model(model=conv_3d7_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv3DModel5(DataGenerator):\n",
    "\n",
    "    def model_structure(self):\n",
    "        #write your model here\n",
    "        #normalization_layer = layers.experimental.preprocessing.Rescaling(1./255, \n",
    "        #input_shape=(img_frames,img_height, img_width, 3))\n",
    "\n",
    "        #model3d = Sequential([normalization_layer])\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(layers.Conv3D(16,(3,3,3), activation=\"relu\",data_format='channels_first', \n",
    "                                input_shape=(len(self.img_idx),self.img_height, self.img_width, 3)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(layers.MaxPool3D())\n",
    "\n",
    "        model.add(layers.Conv3D(32,(3,3,3), activation=\"relu\",))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(layers.MaxPool3D())\n",
    "\n",
    "        #model.add(layers.Conv3D(64,(3,3,3), activation=\"relu\",))\n",
    "        #model.add(BatchNormalization())\n",
    "        #model.add(layers.MaxPool3D())\n",
    "\n",
    "        #model.add(layers.Conv3D(128,(3,3,3), activation=\"relu\",))\n",
    "        #model.add(BatchNormalization())\n",
    "        #model.add(layers.MaxPool3D())\n",
    "\n",
    "        model.add(layers.Flatten())\n",
    "\n",
    "        #model.add(layers.Dense(128, activation=\"relu\"))\n",
    "        #model.add(BatchNormalization())\n",
    "        #model.add(layers.Dropout(0.5))\n",
    "\n",
    "        model.add(layers.Dense(32, activation=\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(layers.Dropout(0.5))\n",
    "\n",
    "        model.add(layers.Dense(5,activation='softmax'))\n",
    "\n",
    "        optimiser = optimizers.Adam(lr=0.001)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 16, 148, 148, 1)   7792      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 16, 148, 148, 1)   4         \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 8, 74, 74, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 6, 72, 72, 32)     896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 6, 72, 72, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 3, 36, 36, 32)     0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 124416)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                3981344   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 3,990,457\n",
      "Trainable params: 3,990,327\n",
      "Non-trainable params: 130\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_3d8=Conv3DModel5()\n",
    "conv_3d8.initialize_parameters(batch_size=20,num_epochs=25,img_height=150,img_width=150)\n",
    "conv_3d8_model=conv_3d8.model_structure()\n",
    "conv_3d8_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.6484 - categorical_accuracy: 0.3333\n",
      "Epoch 00001: val_loss improved from inf to 6.60308, saving model to model_init_2021-06-2421_58_31.599331/model-00001-1.64843-0.33333-6.60308-0.23000.h5\n",
      "34/34 [==============================] - 37s 1s/step - loss: 1.6484 - categorical_accuracy: 0.3333 - val_loss: 6.6031 - val_categorical_accuracy: 0.2300\n",
      "Epoch 2/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.2143 - categorical_accuracy: 0.5083\n",
      "Epoch 00002: val_loss improved from 6.60308 to 2.36125, saving model to model_init_2021-06-2421_58_31.599331/model-00002-1.21429-0.50830-2.36125-0.25000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.2143 - categorical_accuracy: 0.5083 - val_loss: 2.3613 - val_categorical_accuracy: 0.2500\n",
      "Epoch 3/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9618 - categorical_accuracy: 0.6440\n",
      "Epoch 00003: val_loss did not improve from 2.36125\n",
      "34/34 [==============================] - 37s 1s/step - loss: 0.9618 - categorical_accuracy: 0.6440 - val_loss: 2.5294 - val_categorical_accuracy: 0.1800\n",
      "Epoch 4/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.7206 - categorical_accuracy: 0.7919\n",
      "Epoch 00004: val_loss did not improve from 2.36125\n",
      "34/34 [==============================] - 37s 1s/step - loss: 0.7206 - categorical_accuracy: 0.7919 - val_loss: 2.7724 - val_categorical_accuracy: 0.1700\n",
      "Epoch 5/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.5834 - categorical_accuracy: 0.8507\n",
      "Epoch 00005: val_loss did not improve from 2.36125\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.5834 - categorical_accuracy: 0.8507 - val_loss: 2.4591 - val_categorical_accuracy: 0.1900\n",
      "Epoch 6/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.5081 - categorical_accuracy: 0.8914\n",
      "Epoch 00006: val_loss did not improve from 2.36125\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "34/34 [==============================] - 37s 1s/step - loss: 0.5081 - categorical_accuracy: 0.8914 - val_loss: 2.6823 - val_categorical_accuracy: 0.1600\n",
      "Epoch 7/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4068 - categorical_accuracy: 0.9216\n",
      "Epoch 00007: val_loss did not improve from 2.36125\n",
      "34/34 [==============================] - 37s 1s/step - loss: 0.4068 - categorical_accuracy: 0.9216 - val_loss: 2.3996 - val_categorical_accuracy: 0.1500\n",
      "Epoch 8/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4124 - categorical_accuracy: 0.9231\n",
      "Epoch 00008: val_loss improved from 2.36125 to 1.95426, saving model to model_init_2021-06-2421_58_31.599331/model-00008-0.41236-0.92308-1.95426-0.27000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.4124 - categorical_accuracy: 0.9231 - val_loss: 1.9543 - val_categorical_accuracy: 0.2700\n",
      "Epoch 9/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3773 - categorical_accuracy: 0.9367\n",
      "Epoch 00009: val_loss improved from 1.95426 to 1.79296, saving model to model_init_2021-06-2421_58_31.599331/model-00009-0.37727-0.93665-1.79296-0.21000.h5\n",
      "34/34 [==============================] - 37s 1s/step - loss: 0.3773 - categorical_accuracy: 0.9367 - val_loss: 1.7930 - val_categorical_accuracy: 0.2100\n",
      "Epoch 10/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3723 - categorical_accuracy: 0.9367\n",
      "Epoch 00010: val_loss improved from 1.79296 to 1.73416, saving model to model_init_2021-06-2421_58_31.599331/model-00010-0.37225-0.93665-1.73416-0.18000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.3723 - categorical_accuracy: 0.9367 - val_loss: 1.7342 - val_categorical_accuracy: 0.1800\n",
      "Epoch 11/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3593 - categorical_accuracy: 0.9487\n",
      "Epoch 00011: val_loss improved from 1.73416 to 1.44079, saving model to model_init_2021-06-2421_58_31.599331/model-00011-0.35925-0.94872-1.44079-0.34000.h5\n",
      "34/34 [==============================] - 37s 1s/step - loss: 0.3593 - categorical_accuracy: 0.9487 - val_loss: 1.4408 - val_categorical_accuracy: 0.3400\n",
      "Epoch 12/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3506 - categorical_accuracy: 0.9532\n",
      "Epoch 00012: val_loss improved from 1.44079 to 1.09381, saving model to model_init_2021-06-2421_58_31.599331/model-00012-0.35057-0.95324-1.09381-0.52000.h5\n",
      "34/34 [==============================] - 37s 1s/step - loss: 0.3506 - categorical_accuracy: 0.9532 - val_loss: 1.0938 - val_categorical_accuracy: 0.5200\n",
      "Epoch 13/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3429 - categorical_accuracy: 0.9427\n",
      "Epoch 00013: val_loss did not improve from 1.09381\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.3429 - categorical_accuracy: 0.9427 - val_loss: 1.1359 - val_categorical_accuracy: 0.4800\n",
      "Epoch 14/25\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3484 - categorical_accuracy: 0.9394\n",
      "Epoch 00014: val_loss improved from 1.09381 to 0.91446, saving model to model_init_2021-06-2421_58_31.599331/model-00014-0.35218-0.93665-0.91446-0.75000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.3522 - categorical_accuracy: 0.9367 - val_loss: 0.9145 - val_categorical_accuracy: 0.7500\n",
      "Epoch 15/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3275 - categorical_accuracy: 0.9487\n",
      "Epoch 00015: val_loss improved from 0.91446 to 0.83295, saving model to model_init_2021-06-2421_58_31.599331/model-00015-0.32755-0.94872-0.83295-0.73000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.3275 - categorical_accuracy: 0.9487 - val_loss: 0.8329 - val_categorical_accuracy: 0.7300\n",
      "Epoch 16/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3273 - categorical_accuracy: 0.9502\n",
      "Epoch 00016: val_loss improved from 0.83295 to 0.78227, saving model to model_init_2021-06-2421_58_31.599331/model-00016-0.32732-0.95023-0.78227-0.77000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.3273 - categorical_accuracy: 0.9502 - val_loss: 0.7823 - val_categorical_accuracy: 0.7700\n",
      "Epoch 17/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3157 - categorical_accuracy: 0.9563\n",
      "Epoch 00017: val_loss improved from 0.78227 to 0.71777, saving model to model_init_2021-06-2421_58_31.599331/model-00017-0.31571-0.95626-0.71777-0.79000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.3157 - categorical_accuracy: 0.9563 - val_loss: 0.7178 - val_categorical_accuracy: 0.7900\n",
      "Epoch 18/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2912 - categorical_accuracy: 0.9593\n",
      "Epoch 00018: val_loss did not improve from 0.71777\n",
      "34/34 [==============================] - 37s 1s/step - loss: 0.2912 - categorical_accuracy: 0.9593 - val_loss: 0.7190 - val_categorical_accuracy: 0.7900\n",
      "Epoch 19/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2955 - categorical_accuracy: 0.9713\n",
      "Epoch 00019: val_loss improved from 0.71777 to 0.68558, saving model to model_init_2021-06-2421_58_31.599331/model-00019-0.29547-0.97134-0.68558-0.80000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.2955 - categorical_accuracy: 0.9713 - val_loss: 0.6856 - val_categorical_accuracy: 0.8000\n",
      "Epoch 20/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2921 - categorical_accuracy: 0.9623\n",
      "Epoch 00020: val_loss improved from 0.68558 to 0.63855, saving model to model_init_2021-06-2421_58_31.599331/model-00020-0.29214-0.96229-0.63855-0.80000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.2921 - categorical_accuracy: 0.9623 - val_loss: 0.6385 - val_categorical_accuracy: 0.8000\n",
      "Epoch 21/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2832 - categorical_accuracy: 0.9653\n",
      "Epoch 00021: val_loss did not improve from 0.63855\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.2832 - categorical_accuracy: 0.9653 - val_loss: 0.7021 - val_categorical_accuracy: 0.7700\n",
      "Epoch 22/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2588 - categorical_accuracy: 0.9759\n",
      "Epoch 00022: val_loss did not improve from 0.63855\n",
      "34/34 [==============================] - 37s 1s/step - loss: 0.2588 - categorical_accuracy: 0.9759 - val_loss: 0.6883 - val_categorical_accuracy: 0.7700\n",
      "Epoch 23/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2863 - categorical_accuracy: 0.9668\n",
      "Epoch 00023: val_loss did not improve from 0.63855\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.2863 - categorical_accuracy: 0.9668 - val_loss: 0.6461 - val_categorical_accuracy: 0.7800\n",
      "Epoch 24/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2616 - categorical_accuracy: 0.9744\n",
      "Epoch 00024: val_loss improved from 0.63855 to 0.63124, saving model to model_init_2021-06-2421_58_31.599331/model-00024-0.26156-0.97436-0.63124-0.86000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.2616 - categorical_accuracy: 0.9744 - val_loss: 0.6312 - val_categorical_accuracy: 0.8600\n",
      "Epoch 25/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2353 - categorical_accuracy: 0.9804\n",
      "Epoch 00025: val_loss did not improve from 0.63124\n",
      "34/34 [==============================] - 37s 1s/step - loss: 0.2353 - categorical_accuracy: 0.9804 - val_loss: 0.6372 - val_categorical_accuracy: 0.8400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f71a07e5c50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_3d8.train_model(model=conv_3d8_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_48 (Conv3D)           (None, 16, 98, 98, 1)     7792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_73 (Batc (None, 16, 98, 98, 1)     4         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_48 (MaxPooling (None, 8, 49, 49, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_49 (Conv3D)           (None, 6, 47, 47, 32)     896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_74 (Batc (None, 6, 47, 47, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_49 (MaxPooling (None, 3, 23, 23, 32)     0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 50784)             0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 32)                1625120   \n",
      "_________________________________________________________________\n",
      "batch_normalization_75 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 1,634,233\n",
      "Trainable params: 1,634,103\n",
      "Non-trainable params: 130\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_3d9=Conv3DModel5()\n",
    "conv_3d9.initialize_parameters(batch_size=20,num_epochs=35,img_height=100,img_width=100)\n",
    "conv_3d9_model=conv_3d9.model_structure()\n",
    "conv_3d9_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.7319 - categorical_accuracy: 0.3379\n",
      "Epoch 00001: val_loss improved from inf to 1.85345, saving model to model_init_2021-06-2500_47_47.981610/model-00001-1.73194-0.33786-1.85345-0.17000.h5\n",
      "34/34 [==============================] - 34s 992ms/step - loss: 1.7319 - categorical_accuracy: 0.3379 - val_loss: 1.8534 - val_categorical_accuracy: 0.1700\n",
      "Epoch 2/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.3055 - categorical_accuracy: 0.4691\n",
      "Epoch 00002: val_loss did not improve from 1.85345\n",
      "34/34 [==============================] - 33s 969ms/step - loss: 1.3055 - categorical_accuracy: 0.4691 - val_loss: 2.0754 - val_categorical_accuracy: 0.2000\n",
      "Epoch 3/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0290 - categorical_accuracy: 0.6048\n",
      "Epoch 00003: val_loss did not improve from 1.85345\n",
      "34/34 [==============================] - 33s 968ms/step - loss: 1.0290 - categorical_accuracy: 0.6048 - val_loss: 2.6063 - val_categorical_accuracy: 0.2500\n",
      "Epoch 4/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.7776 - categorical_accuracy: 0.7300\n",
      "Epoch 00004: val_loss did not improve from 1.85345\n",
      "34/34 [==============================] - 33s 985ms/step - loss: 0.7776 - categorical_accuracy: 0.7300 - val_loss: 3.0905 - val_categorical_accuracy: 0.2200\n",
      "Epoch 5/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.1139 - categorical_accuracy: 0.5867\n",
      "Epoch 00005: val_loss improved from 1.85345 to 1.65589, saving model to model_init_2021-06-2500_47_47.981610/model-00005-1.11390-0.58673-1.65589-0.47000.h5\n",
      "34/34 [==============================] - 33s 964ms/step - loss: 1.1139 - categorical_accuracy: 0.5867 - val_loss: 1.6559 - val_categorical_accuracy: 0.4700\n",
      "Epoch 6/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.8603 - categorical_accuracy: 0.6817\n",
      "Epoch 00006: val_loss did not improve from 1.65589\n",
      "34/34 [==============================] - 33s 969ms/step - loss: 0.8603 - categorical_accuracy: 0.6817 - val_loss: 1.8553 - val_categorical_accuracy: 0.4500\n",
      "Epoch 7/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6917 - categorical_accuracy: 0.7813\n",
      "Epoch 00007: val_loss did not improve from 1.65589\n",
      "34/34 [==============================] - 33s 974ms/step - loss: 0.6917 - categorical_accuracy: 0.7813 - val_loss: 2.4771 - val_categorical_accuracy: 0.3200\n",
      "Epoch 8/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.5822 - categorical_accuracy: 0.8326\n",
      "Epoch 00008: val_loss did not improve from 1.65589\n",
      "34/34 [==============================] - 33s 976ms/step - loss: 0.5822 - categorical_accuracy: 0.8326 - val_loss: 2.5196 - val_categorical_accuracy: 0.3500\n",
      "Epoch 9/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.5197 - categorical_accuracy: 0.8296\n",
      "Epoch 00009: val_loss did not improve from 1.65589\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "34/34 [==============================] - 33s 970ms/step - loss: 0.5197 - categorical_accuracy: 0.8296 - val_loss: 2.6364 - val_categorical_accuracy: 0.3500\n",
      "Epoch 10/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4182 - categorical_accuracy: 0.8974\n",
      "Epoch 00010: val_loss did not improve from 1.65589\n",
      "34/34 [==============================] - 33s 967ms/step - loss: 0.4182 - categorical_accuracy: 0.8974 - val_loss: 2.5648 - val_categorical_accuracy: 0.3800\n",
      "Epoch 11/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3901 - categorical_accuracy: 0.9020\n",
      "Epoch 00011: val_loss did not improve from 1.65589\n",
      "34/34 [==============================] - 33s 972ms/step - loss: 0.3901 - categorical_accuracy: 0.9020 - val_loss: 2.3516 - val_categorical_accuracy: 0.3800\n",
      "Epoch 12/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4247 - categorical_accuracy: 0.8824\n",
      "Epoch 00012: val_loss did not improve from 1.65589\n",
      "34/34 [==============================] - 33s 975ms/step - loss: 0.4247 - categorical_accuracy: 0.8824 - val_loss: 2.0244 - val_categorical_accuracy: 0.4000\n",
      "Epoch 13/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3674 - categorical_accuracy: 0.9080\n",
      "Epoch 00013: val_loss did not improve from 1.65589\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "34/34 [==============================] - 33s 966ms/step - loss: 0.3674 - categorical_accuracy: 0.9080 - val_loss: 1.6965 - val_categorical_accuracy: 0.4700\n",
      "Epoch 14/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3668 - categorical_accuracy: 0.9125\n",
      "Epoch 00014: val_loss improved from 1.65589 to 1.49428, saving model to model_init_2021-06-2500_47_47.981610/model-00014-0.36684-0.91252-1.49428-0.47000.h5\n",
      "34/34 [==============================] - 33s 970ms/step - loss: 0.3668 - categorical_accuracy: 0.9125 - val_loss: 1.4943 - val_categorical_accuracy: 0.4700\n",
      "Epoch 15/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3749 - categorical_accuracy: 0.9035\n",
      "Epoch 00015: val_loss improved from 1.49428 to 1.40978, saving model to model_init_2021-06-2500_47_47.981610/model-00015-0.37494-0.90347-1.40978-0.49000.h5\n",
      "34/34 [==============================] - 33s 984ms/step - loss: 0.3749 - categorical_accuracy: 0.9035 - val_loss: 1.4098 - val_categorical_accuracy: 0.4900\n",
      "Epoch 16/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3720 - categorical_accuracy: 0.9125\n",
      "Epoch 00016: val_loss improved from 1.40978 to 1.07808, saving model to model_init_2021-06-2500_47_47.981610/model-00016-0.37202-0.91252-1.07808-0.60000.h5\n",
      "34/34 [==============================] - 33s 965ms/step - loss: 0.3720 - categorical_accuracy: 0.9125 - val_loss: 1.0781 - val_categorical_accuracy: 0.6000\n",
      "Epoch 17/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3649 - categorical_accuracy: 0.9110\n",
      "Epoch 00017: val_loss improved from 1.07808 to 1.01068, saving model to model_init_2021-06-2500_47_47.981610/model-00017-0.36490-0.91101-1.01068-0.61000.h5\n",
      "34/34 [==============================] - 33s 969ms/step - loss: 0.3649 - categorical_accuracy: 0.9110 - val_loss: 1.0107 - val_categorical_accuracy: 0.6100\n",
      "Epoch 18/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3625 - categorical_accuracy: 0.9170\n",
      "Epoch 00018: val_loss improved from 1.01068 to 0.85337, saving model to model_init_2021-06-2500_47_47.981610/model-00018-0.36250-0.91704-0.85337-0.69000.h5\n",
      "34/34 [==============================] - 33s 982ms/step - loss: 0.3625 - categorical_accuracy: 0.9170 - val_loss: 0.8534 - val_categorical_accuracy: 0.6900\n",
      "Epoch 19/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3635 - categorical_accuracy: 0.9170\n",
      "Epoch 00019: val_loss improved from 0.85337 to 0.68275, saving model to model_init_2021-06-2500_47_47.981610/model-00019-0.36353-0.91704-0.68275-0.79000.h5\n",
      "34/34 [==============================] - 33s 964ms/step - loss: 0.3635 - categorical_accuracy: 0.9170 - val_loss: 0.6827 - val_categorical_accuracy: 0.7900\n",
      "Epoch 20/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3553 - categorical_accuracy: 0.9020\n",
      "Epoch 00020: val_loss improved from 0.68275 to 0.67230, saving model to model_init_2021-06-2500_47_47.981610/model-00020-0.35525-0.90196-0.67230-0.81000.h5\n",
      "34/34 [==============================] - 33s 974ms/step - loss: 0.3553 - categorical_accuracy: 0.9020 - val_loss: 0.6723 - val_categorical_accuracy: 0.8100\n",
      "Epoch 21/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4010 - categorical_accuracy: 0.9035\n",
      "Epoch 00021: val_loss did not improve from 0.67230\n",
      "34/34 [==============================] - 33s 976ms/step - loss: 0.4010 - categorical_accuracy: 0.9035 - val_loss: 0.6957 - val_categorical_accuracy: 0.7800\n",
      "Epoch 22/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3519 - categorical_accuracy: 0.9246\n",
      "Epoch 00022: val_loss did not improve from 0.67230\n",
      "34/34 [==============================] - 33s 980ms/step - loss: 0.3519 - categorical_accuracy: 0.9246 - val_loss: 0.6756 - val_categorical_accuracy: 0.7700\n",
      "Epoch 23/35\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3741 - categorical_accuracy: 0.9136\n",
      "Epoch 00023: val_loss did not improve from 0.67230\n",
      "34/34 [==============================] - 33s 964ms/step - loss: 0.3743 - categorical_accuracy: 0.9140 - val_loss: 0.6826 - val_categorical_accuracy: 0.8100\n",
      "Epoch 24/35\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3846 - categorical_accuracy: 0.9015\n",
      "Epoch 00024: val_loss improved from 0.67230 to 0.62718, saving model to model_init_2021-06-2500_47_47.981610/model-00024-0.38753-0.90045-0.62718-0.83000.h5\n",
      "34/34 [==============================] - 33s 980ms/step - loss: 0.3875 - categorical_accuracy: 0.9005 - val_loss: 0.6272 - val_categorical_accuracy: 0.8300\n",
      "Epoch 25/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3688 - categorical_accuracy: 0.8974\n",
      "Epoch 00025: val_loss did not improve from 0.62718\n",
      "34/34 [==============================] - 34s 987ms/step - loss: 0.3688 - categorical_accuracy: 0.8974 - val_loss: 0.6372 - val_categorical_accuracy: 0.8200\n",
      "Epoch 26/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3438 - categorical_accuracy: 0.9336\n",
      "Epoch 00026: val_loss did not improve from 0.62718\n",
      "34/34 [==============================] - 33s 985ms/step - loss: 0.3438 - categorical_accuracy: 0.9336 - val_loss: 0.6478 - val_categorical_accuracy: 0.8300\n",
      "Epoch 27/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3446 - categorical_accuracy: 0.9291\n",
      "Epoch 00027: val_loss improved from 0.62718 to 0.60359, saving model to model_init_2021-06-2500_47_47.981610/model-00027-0.34460-0.92911-0.60359-0.86000.h5\n",
      "34/34 [==============================] - 33s 973ms/step - loss: 0.3446 - categorical_accuracy: 0.9291 - val_loss: 0.6036 - val_categorical_accuracy: 0.8600\n",
      "Epoch 28/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3536 - categorical_accuracy: 0.9125\n",
      "Epoch 00028: val_loss did not improve from 0.60359\n",
      "34/34 [==============================] - 34s 989ms/step - loss: 0.3536 - categorical_accuracy: 0.9125 - val_loss: 0.6641 - val_categorical_accuracy: 0.8300\n",
      "Epoch 29/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3415 - categorical_accuracy: 0.9201\n",
      "Epoch 00029: val_loss did not improve from 0.60359\n",
      "34/34 [==============================] - 32s 949ms/step - loss: 0.3415 - categorical_accuracy: 0.9201 - val_loss: 0.6211 - val_categorical_accuracy: 0.8300\n",
      "Epoch 30/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3536 - categorical_accuracy: 0.9095\n",
      "Epoch 00030: val_loss did not improve from 0.60359\n",
      "34/34 [==============================] - 33s 976ms/step - loss: 0.3536 - categorical_accuracy: 0.9095 - val_loss: 0.6436 - val_categorical_accuracy: 0.8300\n",
      "Epoch 31/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3388 - categorical_accuracy: 0.9186\n",
      "Epoch 00031: val_loss did not improve from 0.60359\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "34/34 [==============================] - 34s 1s/step - loss: 0.3388 - categorical_accuracy: 0.9186 - val_loss: 0.6383 - val_categorical_accuracy: 0.8400\n",
      "Epoch 32/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3449 - categorical_accuracy: 0.9170\n",
      "Epoch 00032: val_loss did not improve from 0.60359\n",
      "34/34 [==============================] - 33s 980ms/step - loss: 0.3449 - categorical_accuracy: 0.9170 - val_loss: 0.6299 - val_categorical_accuracy: 0.8500\n",
      "Epoch 33/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3516 - categorical_accuracy: 0.9155\n",
      "Epoch 00033: val_loss did not improve from 0.60359\n",
      "34/34 [==============================] - 33s 969ms/step - loss: 0.3516 - categorical_accuracy: 0.9155 - val_loss: 0.6643 - val_categorical_accuracy: 0.8300\n",
      "Epoch 34/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3302 - categorical_accuracy: 0.9216\n",
      "Epoch 00034: val_loss improved from 0.60359 to 0.53421, saving model to model_init_2021-06-2500_47_47.981610/model-00034-0.33019-0.92157-0.53421-0.91000.h5\n",
      "34/34 [==============================] - 34s 987ms/step - loss: 0.3302 - categorical_accuracy: 0.9216 - val_loss: 0.5342 - val_categorical_accuracy: 0.9100\n",
      "Epoch 35/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3510 - categorical_accuracy: 0.9246\n",
      "Epoch 00035: val_loss did not improve from 0.53421\n",
      "34/34 [==============================] - 33s 969ms/step - loss: 0.3510 - categorical_accuracy: 0.9246 - val_loss: 0.6564 - val_categorical_accuracy: 0.8100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f71245975f8>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_3d9.train_model(model=conv_3d9_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
