{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "import datetime\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, LSTM, Dropout, Flatten, BatchNormalization, Activation, Conv3D, MaxPooling3D, TimeDistributed\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '/home/datasets/Project_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator():\n",
    "    def __init__(self):\n",
    "        'Initialization'\n",
    "        self.train_doc = np.random.permutation(open(DATASET_PATH + 'train.csv').readlines())\n",
    "        self.val_doc = np.random.permutation(open(DATASET_PATH + 'val.csv').readlines())\n",
    "        \n",
    "        self.train_path = DATASET_PATH + 'train'\n",
    "        self.val_path = DATASET_PATH + 'val'\n",
    "        \n",
    "        self.num_train_sequences = len(self.train_doc)\n",
    "        self.num_val_sequences = len(self.val_doc)\n",
    "        \n",
    "        self.img_idx = [0,2,4,6,8,10,12,14,16,18,20,22,24,25,26,27,28,29]\n",
    "    \n",
    "    def initialize_parameters(self,batch_size=10,img_height=100,img_width=100,num_epochs=5,\n",
    "                              n_channels=3,ablation=None,mode='train'):\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.channels = n_channels\n",
    "        self.num_classes = 5\n",
    "        self.frames = 30\n",
    "    \n",
    "    def generator(self,source_path, folder_list, transform=False):\n",
    "        batch_size=self.batch_size\n",
    "        \n",
    "        while True:\n",
    "            t = np.random.permutation(folder_list)\n",
    "            num_batches = np.floor(len(folder_list)/self.batch_size).astype(int)\n",
    "            \n",
    "            for batch in range(num_batches): # we iterate over the number of batches\n",
    "                batch_data, batch_labels = self.fetch_batch(source_path,t,batch,self.batch_size,self.img_idx,transform)\n",
    "                yield batch_data, batch_labels\n",
    "            \n",
    "            pending_batches = (len(folder_list) - num_batches*self.batch_size)\n",
    "            \n",
    "            if pending_batches > 0:\n",
    "                batch_data, batch_labels = self.fetch_batch(source_path,t,batch,pending_batches,self.img_idx,transform)\n",
    "                yield batch_data, batch_labels\n",
    "    \n",
    "    def fetch_batch(self,source_path,t,batch,batch_size,img_idx,transform):\n",
    "        # x is the number of images you use for each video, \n",
    "        # (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "        batch_data = np.zeros((batch_size,len(img_idx),self.img_height,self.img_width,3))\n",
    "        batch_labels = np.zeros((batch_size,5))\n",
    "        \n",
    "        if (transform):\n",
    "            batch_data_affine = np.zeros((batch_size,len(img_idx),self.img_height,self.img_width,3))\n",
    "\n",
    "        for folder in range(batch_size):\n",
    "            # read all the images in the folder\n",
    "            imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) \n",
    "            \n",
    "            img_idx = self.img_idx\n",
    "            \n",
    "            for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                image = cv2.imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "\n",
    "                if image.shape[0] != image.shape[1]:\n",
    "                    image = image[0:120, 10:150]\n",
    "                \n",
    "                image = cv2.resize(image, (self.img_height,self.img_width), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "                image = image/255\n",
    "                \n",
    "                batch_data[folder,idx,:,:,0] = image[:,:,0]\n",
    "                batch_data[folder,idx,:,:,1] = image[:,:,1]\n",
    "                batch_data[folder,idx,:,:,2] = image[:,:,2]\n",
    "                \n",
    "                #Affine transformation to shift image up/down or right/left\n",
    "                if (transform):\n",
    "                    height, width = image.shape[:2]\n",
    "                    tx, ty = width / 4, height / 4\n",
    "                    tx = np.random.randint(-tx,tx)\n",
    "                    ty = np.random.randint(-ty,ty)\n",
    "                    translation_matrix = np.array([[1, 0, tx],\n",
    "                                                   [0, 1, ty]], dtype=np.float32)\n",
    "\n",
    "                    translated_image = cv2.warpAffine(src=image, M=translation_matrix, dsize=(width, height))\n",
    "\n",
    "                    batch_data_affine[folder,idx,:,:,0] = translated_image[:,:,0]\n",
    "                    batch_data_affine[folder,idx,:,:,1] = translated_image[:,:,1]\n",
    "                    batch_data_affine[folder,idx,:,:,2] = translated_image[:,:,2]\n",
    "\n",
    "            batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "\n",
    "        if (transform):\n",
    "            batch_data=np.concatenate([batch_data,batch_data_affine])\n",
    "            batch_labels=np.concatenate([batch_labels,batch_labels])\n",
    "        \n",
    "        return (batch_data, batch_labels)\n",
    "    \n",
    "    def train_model(self,model,transform=False):\n",
    "        train_generator = self.generator(self.train_path, self.train_doc,transform)\n",
    "        val_generator = self.generator(self.val_path, self.val_doc,transform)\n",
    "        \n",
    "        curr_dt_time = datetime.datetime.now()\n",
    "        \n",
    "        model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "        if not os.path.exists(model_name):\n",
    "            os.mkdir(model_name)\n",
    "\n",
    "        filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "        \n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto',save_freq = 'epoch')\n",
    "        \n",
    "        LR = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, verbose=1) # write the REducelronplateau code here\n",
    "        \n",
    "        earlystop = EarlyStopping(monitor=\"val_loss\", min_delta=0,patience=10,verbose=1)\n",
    "        \n",
    "        callbacks_list = [checkpoint, LR, earlystop]\n",
    "        \n",
    "        if (self.num_train_sequences%self.batch_size) == 0:\n",
    "            #steps_per_epoch = np.floor(num_train_sequences/batch_size).astype(int)\n",
    "            steps_per_epoch = int(self.num_train_sequences/self.batch_size)\n",
    "        else:\n",
    "            #steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "            steps_per_epoch = (self.num_train_sequences//self.batch_size) + 1\n",
    "\n",
    "        if (self.num_val_sequences%self.batch_size) == 0:\n",
    "            #validation_steps = np.floor(num_val_sequences/batch_size).astype(int)\n",
    "            validation_steps = int(self.num_val_sequences/self.batch_size)\n",
    "        else:\n",
    "            #validation_steps = (num_val_sequences//batch_size) + 1\n",
    "            validation_steps = (self.num_val_sequences//self.batch_size) + 1\n",
    "        \n",
    "        \n",
    "        history = model.fit(train_generator, \n",
    "                            steps_per_epoch=steps_per_epoch, \n",
    "                            epochs=self.num_epochs, \n",
    "                            verbose=1, \n",
    "                            callbacks=callbacks_list, \n",
    "                            validation_data=val_generator, \n",
    "                            validation_steps=validation_steps, \n",
    "                            class_weight=None, workers=1, initial_epoch=0)\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def define_model(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Convolution 3D Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv3DModel5(DataGenerator):\n",
    "\n",
    "    def model_structure(self):\n",
    "        #write your model here\n",
    "        #normalization_layer = layers.experimental.preprocessing.Rescaling(1./255, \n",
    "        #input_shape=(img_frames,img_height, img_width, 3))\n",
    "\n",
    "        #model3d = Sequential([normalization_layer])\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(layers.Conv3D(16,(3,3,3), activation=\"relu\",data_format='channels_last', \n",
    "                                input_shape=(len(self.img_idx),self.img_height, self.img_width, 3)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(layers.MaxPool3D())\n",
    "\n",
    "        model.add(layers.Conv3D(32,(3,3,3), activation=\"relu\",))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(layers.MaxPool3D())\n",
    "\n",
    "        #model.add(layers.Conv3D(64,(3,3,3), activation=\"relu\",))\n",
    "        #model.add(BatchNormalization())\n",
    "        #model.add(layers.MaxPool3D())\n",
    "\n",
    "        #model.add(layers.Conv3D(128,(3,3,3), activation=\"relu\",))\n",
    "        #model.add(BatchNormalization())\n",
    "        #model.add(layers.MaxPool3D())\n",
    "\n",
    "        model.add(layers.Flatten())\n",
    "\n",
    "        #model.add(layers.Dense(128, activation=\"relu\"))\n",
    "        #model.add(BatchNormalization())\n",
    "        #model.add(layers.Dropout(0.5))\n",
    "\n",
    "        model.add(layers.Dense(32, activation=\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(layers.Dropout(0.5))\n",
    "\n",
    "        model.add(layers.Dense(5,activation='softmax'))\n",
    "\n",
    "        optimiser = optimizers.Adam(lr=0.001)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_8 (Conv3D)            (None, 16, 148, 148, 16)  1312      \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 16, 148, 148, 16)  64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 8, 74, 74, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 6, 72, 72, 32)     13856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 6, 72, 72, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3 (None, 3, 36, 36, 32)     0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 124416)            0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 32)                3981344   \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 3,996,997\n",
      "Trainable params: 3,996,837\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_3d8_1=Conv3DModel5()\n",
    "conv_3d8_1.initialize_parameters(batch_size=20,num_epochs=35,img_height=150,img_width=150)\n",
    "conv_3d8_1_model=conv_3d8_1.model_structure()\n",
    "conv_3d8_1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.4797 - categorical_accuracy: 0.4676\n",
      "Epoch 00001: val_loss improved from inf to 2.00414, saving model to model_init_2021-07-0321_40_10.421795/model-00001-1.47974-0.46757-2.00414-0.19000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.4797 - categorical_accuracy: 0.4676 - val_loss: 2.0041 - val_categorical_accuracy: 0.1900\n",
      "Epoch 2/35\n",
      "33/34 [============================>.] - ETA: 0s - loss: 1.0207 - categorical_accuracy: 0.6348\n",
      "Epoch 00002: val_loss did not improve from 2.00414\n",
      "34/34 [==============================] - 38s 1s/step - loss: 1.0191 - categorical_accuracy: 0.6350 - val_loss: 4.2005 - val_categorical_accuracy: 0.2200\n",
      "Epoch 3/35\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.7144 - categorical_accuracy: 0.7379\n",
      "Epoch 00003: val_loss did not improve from 2.00414\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.7183 - categorical_accuracy: 0.7360 - val_loss: 10.5311 - val_categorical_accuracy: 0.1800\n",
      "Epoch 4/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6253 - categorical_accuracy: 0.7934\n",
      "Epoch 00004: val_loss did not improve from 2.00414\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.6253 - categorical_accuracy: 0.7934 - val_loss: 7.4760 - val_categorical_accuracy: 0.2300\n",
      "Epoch 5/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4527 - categorical_accuracy: 0.8643\n",
      "Epoch 00005: val_loss did not improve from 2.00414\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.4527 - categorical_accuracy: 0.8643 - val_loss: 5.3992 - val_categorical_accuracy: 0.1800\n",
      "Epoch 6/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4689 - categorical_accuracy: 0.8627\n",
      "Epoch 00006: val_loss did not improve from 2.00414\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.4689 - categorical_accuracy: 0.8627 - val_loss: 4.3175 - val_categorical_accuracy: 0.2500\n",
      "Epoch 7/35\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.4059 - categorical_accuracy: 0.8924\n",
      "Epoch 00007: val_loss did not improve from 2.00414\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.4149 - categorical_accuracy: 0.8899 - val_loss: 3.9014 - val_categorical_accuracy: 0.2400\n",
      "Epoch 8/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3895 - categorical_accuracy: 0.8929\n",
      "Epoch 00008: val_loss did not improve from 2.00414\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.3895 - categorical_accuracy: 0.8929 - val_loss: 2.9315 - val_categorical_accuracy: 0.2400\n",
      "Epoch 9/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3438 - categorical_accuracy: 0.8944\n",
      "Epoch 00009: val_loss did not improve from 2.00414\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.3438 - categorical_accuracy: 0.8944 - val_loss: 2.3791 - val_categorical_accuracy: 0.3000\n",
      "Epoch 10/35\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3180 - categorical_accuracy: 0.9318\n",
      "Epoch 00010: val_loss did not improve from 2.00414\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.3273 - categorical_accuracy: 0.9276 - val_loss: 2.0649 - val_categorical_accuracy: 0.3400\n",
      "Epoch 11/35\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3235 - categorical_accuracy: 0.9212\n",
      "Epoch 00011: val_loss improved from 2.00414 to 1.92206, saving model to model_init_2021-07-0321_40_10.421795/model-00011-0.32884-0.92006-1.92206-0.37000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.3288 - categorical_accuracy: 0.9201 - val_loss: 1.9221 - val_categorical_accuracy: 0.3700\n",
      "Epoch 12/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3320 - categorical_accuracy: 0.9020\n",
      "Epoch 00012: val_loss improved from 1.92206 to 1.78149, saving model to model_init_2021-07-0321_40_10.421795/model-00012-0.33197-0.90196-1.78149-0.37000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.3320 - categorical_accuracy: 0.9020 - val_loss: 1.7815 - val_categorical_accuracy: 0.3700\n",
      "Epoch 13/35\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3168 - categorical_accuracy: 0.9242\n",
      "Epoch 00013: val_loss improved from 1.78149 to 1.57607, saving model to model_init_2021-07-0321_40_10.421795/model-00013-0.31715-0.92459-1.57607-0.48000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.3172 - categorical_accuracy: 0.9246 - val_loss: 1.5761 - val_categorical_accuracy: 0.4800\n",
      "Epoch 14/35\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3144 - categorical_accuracy: 0.9242\n",
      "Epoch 00014: val_loss improved from 1.57607 to 1.30658, saving model to model_init_2021-07-0321_40_10.421795/model-00014-0.31399-0.92459-1.30658-0.52000.h5\n",
      "34/34 [==============================] - 39s 1s/step - loss: 0.3140 - categorical_accuracy: 0.9246 - val_loss: 1.3066 - val_categorical_accuracy: 0.5200\n",
      "Epoch 15/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3510 - categorical_accuracy: 0.9095\n",
      "Epoch 00015: val_loss improved from 1.30658 to 1.06475, saving model to model_init_2021-07-0321_40_10.421795/model-00015-0.35103-0.90950-1.06475-0.59000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.3510 - categorical_accuracy: 0.9095 - val_loss: 1.0648 - val_categorical_accuracy: 0.5900\n",
      "Epoch 16/35\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3192 - categorical_accuracy: 0.9227\n",
      "Epoch 00016: val_loss improved from 1.06475 to 0.93775, saving model to model_init_2021-07-0321_40_10.421795/model-00016-0.32090-0.92157-0.93775-0.68000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.3209 - categorical_accuracy: 0.9216 - val_loss: 0.9377 - val_categorical_accuracy: 0.6800\n",
      "Epoch 17/35\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3032 - categorical_accuracy: 0.9409\n",
      "Epoch 00017: val_loss improved from 0.93775 to 0.86712, saving model to model_init_2021-07-0321_40_10.421795/model-00017-0.30337-0.94118-0.86712-0.73000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.3034 - categorical_accuracy: 0.9412 - val_loss: 0.8671 - val_categorical_accuracy: 0.7300\n",
      "Epoch 18/35\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3128 - categorical_accuracy: 0.9212\n",
      "Epoch 00018: val_loss improved from 0.86712 to 0.71733, saving model to model_init_2021-07-0321_40_10.421795/model-00018-0.31278-0.92157-0.71733-0.78000.h5\n",
      "34/34 [==============================] - 37s 1s/step - loss: 0.3128 - categorical_accuracy: 0.9216 - val_loss: 0.7173 - val_categorical_accuracy: 0.7800\n",
      "Epoch 19/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3224 - categorical_accuracy: 0.9050\n",
      "Epoch 00019: val_loss did not improve from 0.71733\n",
      "34/34 [==============================] - 37s 1s/step - loss: 0.3224 - categorical_accuracy: 0.9050 - val_loss: 0.7522 - val_categorical_accuracy: 0.7500\n",
      "Epoch 20/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2824 - categorical_accuracy: 0.9321\n",
      "Epoch 00020: val_loss improved from 0.71733 to 0.62073, saving model to model_init_2021-07-0321_40_10.421795/model-00020-0.28244-0.93213-0.62073-0.80000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.2824 - categorical_accuracy: 0.9321 - val_loss: 0.6207 - val_categorical_accuracy: 0.8000\n",
      "Epoch 21/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3171 - categorical_accuracy: 0.9125\n",
      "Epoch 00021: val_loss improved from 0.62073 to 0.59271, saving model to model_init_2021-07-0321_40_10.421795/model-00021-0.31706-0.91252-0.59271-0.81000.h5\n",
      "34/34 [==============================] - 37s 1s/step - loss: 0.3171 - categorical_accuracy: 0.9125 - val_loss: 0.5927 - val_categorical_accuracy: 0.8100\n",
      "Epoch 22/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3111 - categorical_accuracy: 0.9140\n",
      "Epoch 00022: val_loss did not improve from 0.59271\n",
      "34/34 [==============================] - 37s 1s/step - loss: 0.3111 - categorical_accuracy: 0.9140 - val_loss: 0.6256 - val_categorical_accuracy: 0.7800\n",
      "Epoch 23/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2837 - categorical_accuracy: 0.9336\n",
      "Epoch 00023: val_loss improved from 0.59271 to 0.49386, saving model to model_init_2021-07-0321_40_10.421795/model-00023-0.28371-0.93363-0.49386-0.84000.h5\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.2837 - categorical_accuracy: 0.9336 - val_loss: 0.4939 - val_categorical_accuracy: 0.8400\n",
      "Epoch 24/35\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3058 - categorical_accuracy: 0.9258\n",
      "Epoch 00024: val_loss did not improve from 0.49386\n",
      "34/34 [==============================] - 37s 1s/step - loss: 0.3046 - categorical_accuracy: 0.9261 - val_loss: 0.6341 - val_categorical_accuracy: 0.7900\n",
      "Epoch 25/35\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2879 - categorical_accuracy: 0.9212\n",
      "Epoch 00025: val_loss did not improve from 0.49386\n",
      "34/34 [==============================] - 37s 1s/step - loss: 0.2903 - categorical_accuracy: 0.9186 - val_loss: 0.5201 - val_categorical_accuracy: 0.8100\n",
      "Epoch 26/35\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2762 - categorical_accuracy: 0.9455\n",
      "Epoch 00026: val_loss did not improve from 0.49386\n",
      "34/34 [==============================] - 37s 1s/step - loss: 0.2835 - categorical_accuracy: 0.9427 - val_loss: 0.5349 - val_categorical_accuracy: 0.8100\n",
      "Epoch 27/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3020 - categorical_accuracy: 0.9276\n",
      "Epoch 00027: val_loss did not improve from 0.49386\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.3020 - categorical_accuracy: 0.9276 - val_loss: 0.5396 - val_categorical_accuracy: 0.8000\n",
      "Epoch 28/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2670 - categorical_accuracy: 0.9306\n",
      "Epoch 00028: val_loss did not improve from 0.49386\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.2670 - categorical_accuracy: 0.9306 - val_loss: 0.5085 - val_categorical_accuracy: 0.8400\n",
      "Epoch 29/35\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3058 - categorical_accuracy: 0.9152\n",
      "Epoch 00029: val_loss improved from 0.49386 to 0.45575, saving model to model_init_2021-07-0321_40_10.421795/model-00029-0.30722-0.91554-0.45575-0.81000.h5\n",
      "34/34 [==============================] - 37s 1s/step - loss: 0.3072 - categorical_accuracy: 0.9155 - val_loss: 0.4557 - val_categorical_accuracy: 0.8100\n",
      "Epoch 30/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2751 - categorical_accuracy: 0.9442\n",
      "Epoch 00030: val_loss did not improve from 0.45575\n",
      "34/34 [==============================] - 37s 1s/step - loss: 0.2751 - categorical_accuracy: 0.9442 - val_loss: 0.5461 - val_categorical_accuracy: 0.7800\n",
      "Epoch 31/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2630 - categorical_accuracy: 0.9291\n",
      "Epoch 00031: val_loss did not improve from 0.45575\n",
      "34/34 [==============================] - 37s 1s/step - loss: 0.2630 - categorical_accuracy: 0.9291 - val_loss: 0.5258 - val_categorical_accuracy: 0.8100\n",
      "Epoch 32/35\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2763 - categorical_accuracy: 0.9303\n",
      "Epoch 00032: val_loss did not improve from 0.45575\n",
      "34/34 [==============================] - 37s 1s/step - loss: 0.2760 - categorical_accuracy: 0.9306 - val_loss: 0.4988 - val_categorical_accuracy: 0.8200\n",
      "Epoch 33/35\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3175 - categorical_accuracy: 0.9106\n",
      "Epoch 00033: val_loss did not improve from 0.45575\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.3203 - categorical_accuracy: 0.9080 - val_loss: 0.6528 - val_categorical_accuracy: 0.7300\n",
      "Epoch 34/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2849 - categorical_accuracy: 0.9306\n",
      "Epoch 00034: val_loss improved from 0.45575 to 0.42225, saving model to model_init_2021-07-0321_40_10.421795/model-00034-0.28494-0.93062-0.42225-0.87000.h5\n",
      "34/34 [==============================] - 37s 1s/step - loss: 0.2849 - categorical_accuracy: 0.9306 - val_loss: 0.4222 - val_categorical_accuracy: 0.8700\n",
      "Epoch 35/35\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2834 - categorical_accuracy: 0.9442\n",
      "Epoch 00035: val_loss did not improve from 0.42225\n",
      "34/34 [==============================] - 37s 1s/step - loss: 0.2834 - categorical_accuracy: 0.9442 - val_loss: 0.5059 - val_categorical_accuracy: 0.8200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f099c4664e0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_3d8_1.train_model(model=conv_3d8_1_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Convolution 2D + RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2DModel5(DataGenerator):\n",
    "\n",
    "    def model_structure(self):\n",
    "        \n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(TimeDistributed(layers.Conv2D(16,(3,3), activation=\"relu\"), \n",
    "                                input_shape=(len(self.img_idx),self.img_height, self.img_width, 3)))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        #model.add(layers.Dropout(0.5))\n",
    "        model.add(TimeDistributed(layers.MaxPool2D()))\n",
    "\n",
    "        model.add(TimeDistributed(layers.Conv2D(32,(3,3), activation=\"relu\")))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        #model.add(layers.Dropout(0.5))\n",
    "        model.add(TimeDistributed(layers.MaxPool2D()))\n",
    "        \n",
    "        model.add(TimeDistributed(layers.Conv2D(64,(3,3), activation=\"relu\")))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        #model.add(layers.Dropout(0.5))\n",
    "        model.add(TimeDistributed(layers.MaxPool2D()))\n",
    "\n",
    "        model.add(TimeDistributed(layers.Flatten()))\n",
    "        \n",
    "        model.add(layers.Dense(64, activation=\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(layers.Dropout(0.5))\n",
    "\n",
    "        model.add(layers.Dense(32, activation=\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(layers.Dropout(0.5))\n",
    "        \n",
    "        model.add(layers.Dense(16, activation=\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(layers.Dropout(0.5))\n",
    "        \n",
    "        model.add(layers.GRU(16, return_sequences=False))\n",
    "        #model.add(layers.Dropout(0.5))\n",
    "\n",
    "        model.add(layers.Dense(5,activation='softmax'))\n",
    "\n",
    "        optimiser = optimizers.Adam(lr=0.01)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_127 (TimeDi (None, 18, 98, 98, 16)    448       \n",
      "_________________________________________________________________\n",
      "time_distributed_128 (TimeDi (None, 18, 98, 98, 16)    64        \n",
      "_________________________________________________________________\n",
      "time_distributed_129 (TimeDi (None, 18, 49, 49, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_130 (TimeDi (None, 18, 47, 47, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_131 (TimeDi (None, 18, 47, 47, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_132 (TimeDi (None, 18, 23, 23, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_133 (TimeDi (None, 18, 21, 21, 64)    18496     \n",
      "_________________________________________________________________\n",
      "time_distributed_134 (TimeDi (None, 18, 21, 21, 64)    256       \n",
      "_________________________________________________________________\n",
      "time_distributed_135 (TimeDi (None, 18, 10, 10, 64)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_136 (TimeDi (None, 18, 6400)          0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 18, 64)            409664    \n",
      "_________________________________________________________________\n",
      "batch_normalization_70 (Batc (None, 18, 64)            256       \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 18, 64)            0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 18, 32)            2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_71 (Batc (None, 18, 32)            128       \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 18, 32)            0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 18, 16)            528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 18, 16)            64        \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "gru_16 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 5)                 85        \n",
      "=================================================================\n",
      "Total params: 438,469\n",
      "Trainable params: 438,021\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_2d5=Conv2DModel5()\n",
    "conv_2d5.initialize_parameters(batch_size=20,num_epochs=45,img_height=100,img_width=100)\n",
    "conv_2d5_model=conv_2d5.model_structure()\n",
    "conv_2d5_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "33/34 [============================>.] - ETA: 0s - loss: 1.5808 - categorical_accuracy: 0.2879\n",
      "Epoch 00001: val_loss improved from inf to 2.55047, saving model to model_init_2021-07-0402_44_48.485766/model-00001-1.58128-0.28808-2.55047-0.24000.h5\n",
      "34/34 [==============================] - 33s 982ms/step - loss: 1.5813 - categorical_accuracy: 0.2881 - val_loss: 2.5505 - val_categorical_accuracy: 0.2400\n",
      "Epoch 2/45\n",
      "33/34 [============================>.] - ETA: 0s - loss: 1.3618 - categorical_accuracy: 0.4333\n",
      "Epoch 00002: val_loss did not improve from 2.55047\n",
      "34/34 [==============================] - 34s 992ms/step - loss: 1.3607 - categorical_accuracy: 0.4329 - val_loss: 2.5620 - val_categorical_accuracy: 0.2700\n",
      "Epoch 3/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.1182 - categorical_accuracy: 0.5279\n",
      "Epoch 00003: val_loss improved from 2.55047 to 2.47476, saving model to model_init_2021-07-0402_44_48.485766/model-00003-1.11817-0.52790-2.47476-0.27000.h5\n",
      "34/34 [==============================] - 34s 990ms/step - loss: 1.1182 - categorical_accuracy: 0.5279 - val_loss: 2.4748 - val_categorical_accuracy: 0.2700\n",
      "Epoch 4/45\n",
      "33/34 [============================>.] - ETA: 0s - loss: 1.0320 - categorical_accuracy: 0.6015\n",
      "Epoch 00004: val_loss did not improve from 2.47476\n",
      "34/34 [==============================] - 33s 973ms/step - loss: 1.0341 - categorical_accuracy: 0.6003 - val_loss: 3.1510 - val_categorical_accuracy: 0.2300\n",
      "Epoch 5/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9297 - categorical_accuracy: 0.6456\n",
      "Epoch 00005: val_loss did not improve from 2.47476\n",
      "34/34 [==============================] - 33s 977ms/step - loss: 0.9297 - categorical_accuracy: 0.6456 - val_loss: 3.1895 - val_categorical_accuracy: 0.2900\n",
      "Epoch 6/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.7694 - categorical_accuracy: 0.7270\n",
      "Epoch 00006: val_loss did not improve from 2.47476\n",
      "34/34 [==============================] - 33s 983ms/step - loss: 0.7694 - categorical_accuracy: 0.7270 - val_loss: 3.4200 - val_categorical_accuracy: 0.2800\n",
      "Epoch 7/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6683 - categorical_accuracy: 0.7602\n",
      "Epoch 00007: val_loss improved from 2.47476 to 2.30886, saving model to model_init_2021-07-0402_44_48.485766/model-00007-0.66826-0.76018-2.30886-0.45000.h5\n",
      "34/34 [==============================] - 34s 990ms/step - loss: 0.6683 - categorical_accuracy: 0.7602 - val_loss: 2.3089 - val_categorical_accuracy: 0.4500\n",
      "Epoch 8/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6013 - categorical_accuracy: 0.7858\n",
      "Epoch 00008: val_loss improved from 2.30886 to 2.23148, saving model to model_init_2021-07-0402_44_48.485766/model-00008-0.60132-0.78582-2.23148-0.35000.h5\n",
      "34/34 [==============================] - 33s 965ms/step - loss: 0.6013 - categorical_accuracy: 0.7858 - val_loss: 2.2315 - val_categorical_accuracy: 0.3500\n",
      "Epoch 9/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.5344 - categorical_accuracy: 0.8130\n",
      "Epoch 00009: val_loss did not improve from 2.23148\n",
      "34/34 [==============================] - 34s 990ms/step - loss: 0.5344 - categorical_accuracy: 0.8130 - val_loss: 2.2794 - val_categorical_accuracy: 0.4900\n",
      "Epoch 10/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4920 - categorical_accuracy: 0.8130\n",
      "Epoch 00010: val_loss did not improve from 2.23148\n",
      "34/34 [==============================] - 33s 970ms/step - loss: 0.4920 - categorical_accuracy: 0.8130 - val_loss: 2.5887 - val_categorical_accuracy: 0.4200\n",
      "Epoch 11/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4052 - categorical_accuracy: 0.8507\n",
      "Epoch 00011: val_loss improved from 2.23148 to 1.77569, saving model to model_init_2021-07-0402_44_48.485766/model-00011-0.40521-0.85068-1.77569-0.55000.h5\n",
      "34/34 [==============================] - 33s 977ms/step - loss: 0.4052 - categorical_accuracy: 0.8507 - val_loss: 1.7757 - val_categorical_accuracy: 0.5500\n",
      "Epoch 12/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3418 - categorical_accuracy: 0.8763\n",
      "Epoch 00012: val_loss improved from 1.77569 to 1.10526, saving model to model_init_2021-07-0402_44_48.485766/model-00012-0.34176-0.87632-1.10526-0.72000.h5\n",
      "34/34 [==============================] - 33s 978ms/step - loss: 0.3418 - categorical_accuracy: 0.8763 - val_loss: 1.1053 - val_categorical_accuracy: 0.7200\n",
      "Epoch 13/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3520 - categorical_accuracy: 0.8884\n",
      "Epoch 00013: val_loss did not improve from 1.10526\n",
      "34/34 [==============================] - 33s 976ms/step - loss: 0.3520 - categorical_accuracy: 0.8884 - val_loss: 1.6786 - val_categorical_accuracy: 0.6300\n",
      "Epoch 14/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2495 - categorical_accuracy: 0.9246\n",
      "Epoch 00014: val_loss did not improve from 1.10526\n",
      "34/34 [==============================] - 33s 965ms/step - loss: 0.2495 - categorical_accuracy: 0.9246 - val_loss: 1.8581 - val_categorical_accuracy: 0.5500\n",
      "Epoch 15/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2144 - categorical_accuracy: 0.9231\n",
      "Epoch 00015: val_loss did not improve from 1.10526\n",
      "34/34 [==============================] - 33s 978ms/step - loss: 0.2144 - categorical_accuracy: 0.9231 - val_loss: 1.4319 - val_categorical_accuracy: 0.6100\n",
      "Epoch 16/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2261 - categorical_accuracy: 0.9306\n",
      "Epoch 00016: val_loss did not improve from 1.10526\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "34/34 [==============================] - 34s 991ms/step - loss: 0.2261 - categorical_accuracy: 0.9306 - val_loss: 1.7373 - val_categorical_accuracy: 0.6200\n",
      "Epoch 17/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1439 - categorical_accuracy: 0.9548\n",
      "Epoch 00017: val_loss did not improve from 1.10526\n",
      "34/34 [==============================] - 33s 973ms/step - loss: 0.1439 - categorical_accuracy: 0.9548 - val_loss: 1.5929 - val_categorical_accuracy: 0.6300\n",
      "Epoch 18/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1110 - categorical_accuracy: 0.9653\n",
      "Epoch 00018: val_loss improved from 1.10526 to 0.77787, saving model to model_init_2021-07-0402_44_48.485766/model-00018-0.11101-0.96531-0.77787-0.76000.h5\n",
      "34/34 [==============================] - 33s 968ms/step - loss: 0.1110 - categorical_accuracy: 0.9653 - val_loss: 0.7779 - val_categorical_accuracy: 0.7600\n",
      "Epoch 19/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0859 - categorical_accuracy: 0.9789\n",
      "Epoch 00019: val_loss did not improve from 0.77787\n",
      "34/34 [==============================] - 33s 973ms/step - loss: 0.0859 - categorical_accuracy: 0.9789 - val_loss: 1.0518 - val_categorical_accuracy: 0.7400\n",
      "Epoch 20/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1006 - categorical_accuracy: 0.9653\n",
      "Epoch 00020: val_loss did not improve from 0.77787\n",
      "34/34 [==============================] - 33s 981ms/step - loss: 0.1006 - categorical_accuracy: 0.9653 - val_loss: 1.0411 - val_categorical_accuracy: 0.7200\n",
      "Epoch 21/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0753 - categorical_accuracy: 0.9774\n",
      "Epoch 00021: val_loss did not improve from 0.77787\n",
      "34/34 [==============================] - 33s 977ms/step - loss: 0.0753 - categorical_accuracy: 0.9774 - val_loss: 0.9751 - val_categorical_accuracy: 0.7400\n",
      "Epoch 22/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0858 - categorical_accuracy: 0.9744\n",
      "Epoch 00022: val_loss improved from 0.77787 to 0.60434, saving model to model_init_2021-07-0402_44_48.485766/model-00022-0.08576-0.97436-0.60434-0.81000.h5\n",
      "34/34 [==============================] - 33s 976ms/step - loss: 0.0858 - categorical_accuracy: 0.9744 - val_loss: 0.6043 - val_categorical_accuracy: 0.8100\n",
      "Epoch 23/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0729 - categorical_accuracy: 0.9849\n",
      "Epoch 00023: val_loss did not improve from 0.60434\n",
      "34/34 [==============================] - 33s 983ms/step - loss: 0.0729 - categorical_accuracy: 0.9849 - val_loss: 0.8961 - val_categorical_accuracy: 0.7500\n",
      "Epoch 24/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0797 - categorical_accuracy: 0.9729\n",
      "Epoch 00024: val_loss did not improve from 0.60434\n",
      "34/34 [==============================] - 33s 968ms/step - loss: 0.0797 - categorical_accuracy: 0.9729 - val_loss: 1.1560 - val_categorical_accuracy: 0.7200\n",
      "Epoch 25/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0496 - categorical_accuracy: 0.9894\n",
      "Epoch 00025: val_loss did not improve from 0.60434\n",
      "34/34 [==============================] - 33s 977ms/step - loss: 0.0496 - categorical_accuracy: 0.9894 - val_loss: 0.7721 - val_categorical_accuracy: 0.7900\n",
      "Epoch 26/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0367 - categorical_accuracy: 0.9910\n",
      "Epoch 00026: val_loss did not improve from 0.60434\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "34/34 [==============================] - 33s 983ms/step - loss: 0.0367 - categorical_accuracy: 0.9910 - val_loss: 0.9935 - val_categorical_accuracy: 0.7600\n",
      "Epoch 27/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0624 - categorical_accuracy: 0.9804\n",
      "Epoch 00027: val_loss did not improve from 0.60434\n",
      "34/34 [==============================] - 33s 969ms/step - loss: 0.0624 - categorical_accuracy: 0.9804 - val_loss: 1.0657 - val_categorical_accuracy: 0.7200\n",
      "Epoch 28/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1001 - categorical_accuracy: 0.9608\n",
      "Epoch 00028: val_loss did not improve from 0.60434\n",
      "34/34 [==============================] - 33s 979ms/step - loss: 0.1001 - categorical_accuracy: 0.9608 - val_loss: 0.9486 - val_categorical_accuracy: 0.7800\n",
      "Epoch 29/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0696 - categorical_accuracy: 0.9864\n",
      "Epoch 00029: val_loss did not improve from 0.60434\n",
      "34/34 [==============================] - 33s 967ms/step - loss: 0.0696 - categorical_accuracy: 0.9864 - val_loss: 0.8919 - val_categorical_accuracy: 0.7700\n",
      "Epoch 30/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0586 - categorical_accuracy: 0.9864\n",
      "Epoch 00030: val_loss did not improve from 0.60434\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "34/34 [==============================] - 33s 970ms/step - loss: 0.0586 - categorical_accuracy: 0.9864 - val_loss: 0.8563 - val_categorical_accuracy: 0.7900\n",
      "Epoch 31/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0584 - categorical_accuracy: 0.9864\n",
      "Epoch 00031: val_loss did not improve from 0.60434\n",
      "34/34 [==============================] - 34s 986ms/step - loss: 0.0584 - categorical_accuracy: 0.9864 - val_loss: 0.8892 - val_categorical_accuracy: 0.7900\n",
      "Epoch 32/45\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0713 - categorical_accuracy: 0.9774\n",
      "Epoch 00032: val_loss did not improve from 0.60434\n",
      "34/34 [==============================] - 34s 994ms/step - loss: 0.0713 - categorical_accuracy: 0.9774 - val_loss: 0.8267 - val_categorical_accuracy: 0.7900\n",
      "Epoch 00032: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff38849c2b0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_2d5.train_model(model=conv_2d5_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
